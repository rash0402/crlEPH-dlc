---
title: "Social Value in Active Inference: Theory and Implementation"
subtitle: "Active Inferenceã«ãŠã‘ã‚‹ç¤¾ä¼šçš„ä¾¡å€¤ã®å®šå¼åŒ–ã¨Hazeå¤‰èª¿ã¨ã®çµ±åˆ"
type: Technical_Note
status: ğŸŸ¢ Active
version: 1.2
date_created: 2025-11-25
date_modified: 2025-11-25
revision_note: "SPM-based feature functions (v1.1â†’1.2)"
author: "Hiroshi Igarashi"
institution: "Tokyo Denki University"
keywords:
  - Active Inference
  - Social Value
  - Free Energy Principle
  - Pragmatic Value
  - Shepherding
  - Multi-agent Systems
  - Differentiable Prediction
  - SPM
  - Perceptual Grounding
---

# Social Value in Active Inference: Theory and Implementation

> [!ABSTRACT]
> **Purpose**: æœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã€Active Inferenceã«ãŠã‘ã‚‹Social Valueï¼ˆç¤¾ä¼šçš„ä¾¡å€¤ï¼‰é …ã®ç†è«–çš„åŸºç›¤ã¨å®Ÿè£…æ–¹æ³•ã‚’è§£èª¬ã™ã‚‹ã€‚Free Energy Principleã®åŸºç¤ã‹ã‚‰å§‹ã‚ã€Expected Free Energy (EFE)ã®å®šå¼åŒ–ã€Pragmatic Valueã¨ã—ã¦ã®Social Valueã®å°å‡ºã€ãã—ã¦Hazeå¤‰èª¿ã¨ã®çµ±åˆæ–¹æ³•ã‚’å­¦è¡“çš„ã«å³å¯†ã«èª¬æ˜ã™ã‚‹ã€‚Shepherdingã‚¿ã‚¹ã‚¯ã¸ã®å¿œç”¨ã‚’å…·ä½“ä¾‹ã¨ã—ã¦ç¤ºã™ã€‚

---

## 0. Executive Summary

### ä¸»è¦ãªæ¦‚å¿µ

**Social Value**ã¨ã¯ã€Active Inferenceãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«ãŠã„ã¦**ä»–ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã®ç©ºé–“çš„ãƒ»ç¤¾ä¼šçš„é–¢ä¿‚æ€§ã‚’ç¶­æŒãƒ»å½¢æˆã™ã‚‹å‹•æ©Ÿ**ã‚’è¡¨ç¾ã™ã‚‹Pragmatic Valueé …ã§ã‚ã‚‹ã€‚

**3ã¤ã®é‡è¦ãªæ€§è³ª**ï¼š

1. **Pragmatic Valueã®ä¸€ç¨®**: Epistemic Valueï¼ˆèªè­˜çš„ä¾¡å€¤ï¼‰ã¨ã¯ç‹¬ç«‹ã—ãŸã€ç›®æ¨™æŒ‡å‘çš„ãªå‹•æ©Ÿ
2. **Hazeã¨ç›¸è£œçš„**: Hazeã¯çŸ¥è¦šã®ç²¾åº¦ã‚’å¤‰èª¿ã€Social Valueã¯è¡Œå‹•ã®å‹•æ©Ÿã‚’æä¾›
3. **Compactnessä¸å¤‰æ€§ã®è§£æ±º**: åç™ºåŠ›ã®ã¿ã§ã¯ä¸å¯èƒ½ãªé›†ç´„è¡Œå‹•ã‚’å®Ÿç¾

**å¿œç”¨é ˜åŸŸ**ï¼š
- Shepherdingï¼ˆç‰§ç¾Šã‚¿ã‚¹ã‚¯ï¼‰
- Flockingï¼ˆç¾¤ã‚Œè¡Œå‹•ï¼‰
- Formation Controlï¼ˆéšŠåˆ—åˆ¶å¾¡ï¼‰
- Crowd Evacuationï¼ˆé¿é›£èª˜å°ï¼‰

---

## 1. Free Energy Principle ã®åŸºç¤

### 1.1 è‡ªç”±ã‚¨ãƒãƒ«ã‚®ãƒ¼ã®å®šç¾©

Free Energy Principle (FEP)ã¯ã€ç”Ÿç‰©ã‚·ã‚¹ãƒ†ãƒ ãŒ**å¤‰åˆ†è‡ªç”±ã‚¨ãƒãƒ«ã‚®ãƒ¼ (Variational Free Energy, VFE)** ã‚’æœ€å°åŒ–ã™ã‚‹ã“ã¨ã§ç’°å¢ƒã¨ã®ç›¸äº’ä½œç”¨ã‚’è¡Œã†ã¨ã„ã†çµ±ä¸€ç†è«–ã§ã‚ã‚‹ï¼ˆFriston, 2010ï¼‰ã€‚

**å¤‰åˆ†è‡ªç”±ã‚¨ãƒãƒ«ã‚®ãƒ¼**:

$$
\boxed{F = \mathbb{E}_{q(s)}[\log q(s) - \log p(o, s)] = D_{KL}[q(s) || p(s|o)] - \log p(o)}
$$

ã“ã“ã§ï¼š
- $s$: éš ã‚ŒçŠ¶æ…‹ï¼ˆç’°å¢ƒã®çœŸã®çŠ¶æ…‹ï¼‰
- $o$: è¦³æ¸¬ï¼ˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒçŸ¥è¦šã™ã‚‹æƒ…å ±ï¼‰
- $q(s)$: éš ã‚ŒçŠ¶æ…‹ã®è¿‘ä¼¼äº‹å¾Œåˆ†å¸ƒï¼ˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ä¿¡å¿µï¼‰
- $p(s|o)$: çœŸã®äº‹å¾Œåˆ†å¸ƒ
- $p(o)$: ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ï¼ˆè¦³æ¸¬ã®å‘¨è¾ºå°¤åº¦ï¼‰

**ç›´æ„Ÿçš„è§£é‡ˆ**:
- VFEã¯ã€ŒçœŸã®äº‹å¾Œåˆ†å¸ƒã€ã¨ã€Œã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ä¿¡å¿µã€ã®ä¹–é›¢ï¼ˆKLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ï¼‰ã‚’æ¸¬ã‚‹
- VFEã‚’æœ€å°åŒ– = ã‚ˆã‚Šæ­£ç¢ºãªä¿¡å¿µã‚’æŒã¤ = äºˆæ¸¬èª¤å·®ã‚’æ¸›ã‚‰ã™

### 1.2 è‡ªç”±ã‚¨ãƒãƒ«ã‚®ãƒ¼ã®åˆ†è§£

VFEã¯2ã¤ã®é …ã«åˆ†è§£ã•ã‚Œã‚‹ï¼š

$$
F = \underbrace{\mathbb{E}_{q(s)}[\log q(s) - \log p(s)]}_{\text{Complexity}} - \underbrace{\mathbb{E}_{q(s)}[\log p(o|s)]}_{\text{Accuracy}}
$$

**Complexityé …**: äº‹å‰åˆ†å¸ƒã‹ã‚‰ã®é€¸è„±ï¼ˆã‚ªãƒƒã‚«ãƒ ã®å‰ƒåˆ€ï¼‰

**Accuracyé …**: è¦³æ¸¬ã®èª¬æ˜åº¦ï¼ˆäºˆæ¸¬ç²¾åº¦ï¼‰

ã“ã®åˆ†è§£ã«ã‚ˆã‚Šã€FEPã¯ã€Œã‚·ãƒ³ãƒ—ãƒ«ã‹ã¤æ­£ç¢ºãªãƒ¢ãƒ‡ãƒ«ã€ã‚’è¿½æ±‚ã™ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚

### 1.3 çŸ¥è¦šã¨è¡Œå‹•ã®çµ±ä¸€

FEPã¯çŸ¥è¦šï¼ˆPerceptionï¼‰ã¨è¡Œå‹•ï¼ˆActionï¼‰ã‚’çµ±ä¸€çš„ã«æ‰±ã†ï¼š

**çŸ¥è¦š**: $q(s)$ ã‚’æ›´æ–°ã—ã¦VFEã‚’æœ€å°åŒ–ï¼ˆä¿¡å¿µæ›´æ–°ï¼‰

**è¡Œå‹•**: $o$ ã‚’å¤‰åŒ–ã•ã›ã¦VFEã‚’æœ€å°åŒ–ï¼ˆèƒ½å‹•çš„æ¨è«–ã€Active Inferenceï¼‰

ã“ã®çµ±ä¸€ã«ã‚ˆã‚Šã€ã€Œä¸–ç•Œã‚’ç†è§£ã™ã‚‹ï¼ˆçŸ¥è¦šï¼‰ã€ã¨ã€Œä¸–ç•Œã‚’å¤‰ãˆã‚‹ï¼ˆè¡Œå‹•ï¼‰ã€ãŒåŒã˜åŸç†ï¼ˆVFEæœ€å°åŒ–ï¼‰ã§èª¬æ˜ã•ã‚Œã‚‹ã€‚

---

## 2. Active Inference ã¨ Expected Free Energy

### 2.1 Expected Free Energy (EFE) ã®å®šç¾©

Active Inferenceã§ã¯ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯**å°†æ¥ã®è¡Œå‹•**ã‚’é¸æŠã™ã‚‹éš›ã«ã€**Expected Free Energy (EFE)** ã‚’æœ€å°åŒ–ã™ã‚‹ï¼ˆFriston et al., 2015ï¼‰ã€‚

$$
\boxed{G(\pi) = \mathbb{E}_{q(o_{\tau}, s_{\tau}|\pi)} \left[ \log q(s_{\tau}|o_{\tau}, \pi) - \log p(o_{\tau}, s_{\tau}) \right]}
$$

ã“ã“ã§ï¼š
- $\pi$: è¡Œå‹•æ–¹ç­–ï¼ˆaction policyï¼‰
- $\tau$: å°†æ¥ã®æ™‚åˆ»
- $q(o_{\tau}, s_{\tau}|\pi)$: æ–¹ç­– $\pi$ ã«å¾“ã£ãŸå ´åˆã®äºˆæ¸¬åˆ†å¸ƒ

**VFEã¨ã®é•ã„**:
- **VFE**: ç¾åœ¨ã®è¦³æ¸¬ã«å¯¾ã™ã‚‹ä¿¡å¿µã®èª¤å·®ï¼ˆçŸ¥è¦šã®å•é¡Œï¼‰
- **EFE**: å°†æ¥ã®è¦³æ¸¬ã«å¯¾ã™ã‚‹æœŸå¾…èª¤å·®ï¼ˆè¡Œå‹•é¸æŠã®å•é¡Œï¼‰

### 2.2 EFE ã®åˆ†è§£: Epistemic vs Pragmatic

EFEã¯2ã¤ã®é …ã«åˆ†è§£ã•ã‚Œã‚‹ï¼š

$$
G(\pi) = \underbrace{\mathbb{E}_{q(o_{\tau}|\pi)} [D_{KL}[q(s_{\tau}|o_{\tau}, \pi) || q(s_{\tau}|\pi)]]}_{\text{Epistemic Value (æƒ…å ±ç²å¾—)}} - \underbrace{\mathbb{E}_{q(o_{\tau}|\pi)} [D_{KL}[q(o_{\tau}|\pi) || p^*(o_{\tau})]]}_{\text{Pragmatic Value (ç›®æ¨™é”æˆ)}}
$$

#### Epistemic Valueï¼ˆèªè­˜çš„ä¾¡å€¤ï¼‰

**æ„å‘³**: ã€Œã“ã®è¡Œå‹•ã§ä¸ç¢ºå®Ÿæ€§ã‚’æ¸›ã‚‰ã›ã‚‹ã‹ï¼Ÿã€

$$
\mathcal{I}(\pi) = \mathbb{E}_{q(o_{\tau}|\pi)} [D_{KL}[q(s_{\tau}|o_{\tau}, \pi) || q(s_{\tau}|\pi)]]
$$

- è¡Œå‹•å¾Œã®ä¿¡å¿µ $q(s_{\tau}|o_{\tau}, \pi)$ ã¨è¡Œå‹•å‰ã®ä¿¡å¿µ $q(s_{\tau}|\pi)$ ã®å·®
- **æƒ…å ±ç²å¾—ï¼ˆInformation Gainï¼‰**ã«ç›¸å½“
- æ¢ç´¢è¡Œå‹•ã‚’é§†å‹•ã™ã‚‹

**å…·ä½“ä¾‹ï¼ˆEPHï¼‰**:
- SPMã®å æœ‰ãƒãƒ£ãƒãƒ«ãŒä¸ç¢ºå®Ÿï¼ˆHazeé«˜ï¼‰ â†’ ç§»å‹•ã—ã¦ç¢ºèªã—ãŸã„
- éšœå®³ç‰©ãŒå¤šã„é ˜åŸŸ â†’ æ…é‡ã«ç§»å‹•ã—ã¦è¡çªã‚’é¿ã‘ãŸã„

#### Pragmatic Valueï¼ˆå®Ÿç”¨çš„ä¾¡å€¤ï¼‰

**æ„å‘³**: ã€Œã“ã®è¡Œå‹•ã§ç›®æ¨™ã«è¿‘ã¥ã‘ã‚‹ã‹ï¼Ÿã€

$$
\mathcal{P}(\pi) = -\mathbb{E}_{q(o_{\tau}|\pi)} [D_{KL}[q(o_{\tau}|\pi) || p^*(o_{\tau})]]
$$

- äºˆæ¸¬ã•ã‚Œã‚‹è¦³æ¸¬ $q(o_{\tau}|\pi)$ ã¨æœ›ã¾ã—ã„è¦³æ¸¬ $p^*(o_{\tau})$ ã®å·®
- **Prior Preferenceï¼ˆäº‹å‰å¥½ã¿ï¼‰**ã«ã‚ˆã‚‹ç›®æ¨™æŒ‡å‘
- æ´»ç”¨è¡Œå‹•ã‚’é§†å‹•ã™ã‚‹

**å…·ä½“ä¾‹ï¼ˆEPHï¼‰**:
- ç›®æ¨™åœ°ç‚¹ã«åˆ°é”ã—ãŸã„
- ç¾Šã‚’ç‰¹å®šã®å ´æ‰€ã«é›†ã‚ãŸã„ â† **Social Valueã¯ã“ã“**

### 2.3 EFEæœ€å°åŒ–ã«ã‚ˆã‚‹è¡Œå‹•é¸æŠ

æœ€é©ãªè¡Œå‹•ã¯ã€EFEã‚’æœ€å°åŒ–ã™ã‚‹æ–¹ç­– $\pi^*$ ã¨ã—ã¦é¸æŠã•ã‚Œã‚‹ï¼š

$$
\pi^* = \arg\min_{\pi} G(\pi)
$$

å®Ÿè£…ä¸Šã¯ã€å‹¾é…é™ä¸‹æ³•ã«ã‚ˆã‚‹æœ€é©åŒ–ï¼š

$$
a_{t+1} = a_t - \eta \nabla_a G(a)
$$

ã“ã“ã§ $\eta$ ã¯å­¦ç¿’ç‡ã€$\nabla_a G(a)$ ã¯EFEã®è¡Œå‹•ã«é–¢ã™ã‚‹å‹¾é…ã€‚

---

## 3. Social Value ã®å®šå¼åŒ–

### 3.1 Social Value ã¨ã¯ä½•ã‹

**Social Value**ã¯ã€**Pragmatic Valueã®ä¸€ç¨®**ã§ã‚ã‚Šã€ä»¥ä¸‹ã®ã‚ˆã†ãªã€Œä»–ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã®é–¢ä¿‚æ€§ã«é–¢ã™ã‚‹ç›®æ¨™ã€ã‚’è¡¨ç¾ã™ã‚‹ï¼š

1. **é›†ç´„ï¼ˆAggregationï¼‰**: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåŒå£«ãŒé©åº¦ã«é›†ã¾ã‚‹ã“ã¨
2. **åˆ†æ•£ï¼ˆDispersionï¼‰**: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåŒå£«ãŒé©åº¦ã«é›¢ã‚Œã‚‹ã“ã¨
3. **éšŠå½¢ç¶­æŒï¼ˆFormationï¼‰**: ç‰¹å®šã®ç©ºé–“é…ç½®ã‚’ä¿ã¤ã“ã¨
4. **èª˜å°ï¼ˆGuidanceï¼‰**: ä»–ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ç‰¹å®šã®å ´æ‰€ã«å°ãã“ã¨

### 3.2 Prior Preference ã¨ã—ã¦ã®å®šå¼åŒ–

Active Inferenceã§ã¯ã€Pragmatic Valueã‚’**æœ›ã¾ã—ã„çŠ¶æ…‹ã®äº‹å‰åˆ†å¸ƒ** $p^*(s)$ ã¨ã—ã¦è¡¨ç¾ã™ã‚‹ï¼š

$$
\mathcal{P} = -\mathbb{E}_{q(s_{\tau}|\pi)} [\log p^*(s_{\tau})]
$$

**Prior Preference** $p^*(s)$ ã¯ã€ã€Œã“ã†ãªã£ã¦ã»ã—ã„ã€ã¨ã„ã†çŠ¶æ…‹ã®ç¢ºç‡åˆ†å¸ƒï¼š
- $p^*(s)$ ãŒé«˜ã„çŠ¶æ…‹ = æœ›ã¾ã—ã„çŠ¶æ…‹
- $p^*(s)$ ãŒä½ã„çŠ¶æ…‹ = é¿ã‘ãŸã„çŠ¶æ…‹

**å…·ä½“ä¾‹ï¼ˆShepherdingï¼‰**:
- æœ›ã¾ã—ã„çŠ¶æ…‹: ç¾ŠãŒé›†ã¾ã‚Šã€ç›®æ¨™åœ°ç‚¹ã«è¿‘ã„
- é¿ã‘ãŸã„çŠ¶æ…‹: ç¾ŠãŒæ•£ã‚‰ã°ã‚Šã€ç›®æ¨™ã‹ã‚‰é ã„

### 3.3 Social Value ã®ä¸€èˆ¬å½¢ã¨è¡Œå‹•ä¾å­˜æ€§

**é‡è¦ãªåŸå‰‡**:

1. **è¡Œå‹•ä¾å­˜æ€§**: Social Valueã¯**è¡Œå‹•$a$ã«ä¾å­˜**ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ï¼ˆ$\nabla_a M_{\text{social}} \neq 0$ï¼‰
2. **çŸ¥è¦šçš„ä¸€è²«æ€§**: Social Valueã¯**SPMï¼ˆçŸ¥è¦šè¡¨ç¾ï¼‰ã‹ã‚‰è¨ˆç®—**ã™ã‚‹ã¹ã
3. **ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä¸­å¿ƒæ€§**: å…¨çŸ¥çš„ãªè¦–ç‚¹ã§ã¯ãªãã€è‡ªå·±ã®çŸ¥è¦šã«åŸºã¥ã

$$
\boxed{M_{\text{social}}(a) = \sum_{i} \lambda_i \cdot f_i(\text{SPM}(a))}
$$

ã“ã“ã§ï¼š
- $a$: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è¡Œå‹•ï¼ˆé€Ÿåº¦ãƒ™ã‚¯ãƒˆãƒ«ï¼‰
- $\text{SPM}(a)$: è¡Œå‹•$a$ã«ã‚ˆã‚‹**å°†æ¥ã®SPM**ï¼ˆäºˆæ¸¬ã•ã‚ŒãŸçŸ¥è¦šï¼‰
- $f_i(\text{SPM})$: SPMã‹ã‚‰è¨ˆç®—ã•ã‚Œã‚‹ç‰¹å¾´é–¢æ•°
- $\lambda_i$: å„ç›®æ¨™ã®é‡ã¿

**å› æœé€£é–ï¼ˆSPMãƒ™ãƒ¼ã‚¹ï¼‰**:
```
è¡Œå‹• a
  â†“
è‡ªå·±ã®å°†æ¥ä½ç½®ãƒ»é€Ÿåº¦ (p_future, v_future)
  â†“
SPMäºˆæ¸¬ (GRUã¾ãŸã¯1-step forward simulation)
  â†“
ç‰¹å¾´é–¢æ•° f_i(SPM_predicted)
  â†“
M_social(a)
```

ã“ã®å®šå¼åŒ–ã«ã‚ˆã‚Šï¼š
- **å‹¾é…è¨ˆç®—ãŒè‡ªç„¶**: SPMäºˆæ¸¬ã¯å¾®åˆ†å¯èƒ½ â†’ $\nabla_a M_{\text{social}}$ ãŒè¨ˆç®—å¯èƒ½
- **GRUäºˆæ¸¬ã¨ã®æ•´åˆ**: Phase 2ã§å®Ÿè£…æ¸ˆã¿ã®SPMäºˆæ¸¬å™¨ã‚’ç›´æ¥åˆ©ç”¨
- **ç”Ÿç‰©å­¦çš„å¦¥å½“æ€§**: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯è‡ªèº«ã®çŸ¥è¦šï¼ˆSPMï¼‰ã®ã¿ã‹ã‚‰æ„æ€æ±ºå®š

**SPMãƒ™ãƒ¼ã‚¹ã®ä¸»è¦ç‰¹å¾´é–¢æ•°**:

#### 1. Angular Compactnessï¼ˆè§’åº¦æ–¹å‘ã®å¯†é›†åº¦ï¼‰

**Occupancyãƒãƒ£ãƒãƒ«ã®è§’åº¦åˆ†å¸ƒã®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼**:

$$
f_{\text{compact}}^{\text{angular}}(\text{SPM}) = -\sum_{\theta=1}^{N_\theta} P(\theta) \log P(\theta)
$$

ã“ã“ã§ï¼š
$$
P(\theta) = \frac{\sum_{r} \text{SPM}_{\text{occ}}[r, \theta]}{\sum_{r,\theta'} \text{SPM}_{\text{occ}}[r, \theta']}
$$

- **æ„å‘³**: è§’åº¦æ–¹å‘ã®å æœ‰ç¢ºç‡åˆ†å¸ƒã®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼
- **ä½ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼** â†’ ç‰¹å®šã®è§’åº¦ã«é›†ä¸­ â†’ ç¾ŠãŒé›†ç´„ã•ã‚Œã¦ã„ã‚‹
- **é«˜ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼** â†’ å…¨æ–¹å‘ã«åˆ†æ•£ â†’ ç¾ŠãŒæ•£ã‚‰ã°ã£ã¦ã„ã‚‹

**ä»£æ›¿æ¡ˆï¼ˆè§’åº¦åˆ†æ•£ï¼‰**:

$$
f_{\text{compact}}^{\text{var}}(\text{SPM}) = \text{Var}_{\theta} \left[ \sum_r \text{SPM}_{\text{occ}}[r, \theta] \right]
$$

- é«˜åˆ†æ•£ = ç‰¹å®šæ–¹å‘ã«ååœ¨ï¼ˆçŠ¶æ³ã«å¿œã˜ã¦è‰¯ã„/æ‚ªã„ï¼‰
- ä½åˆ†æ•£ = å‡ç­‰ã«åˆ†å¸ƒï¼ˆæ•£ã‚‰ã°ã£ã¦ã„ã‚‹ï¼‰

#### 2. Goal Direction Alignmentï¼ˆç›®æ¨™æ–¹å‘ã¨ã®æ•´åˆæ€§ï¼‰

**ç›®æ¨™æ–¹å‘ã¸ã®ç¾Šã®é…ç½®è©•ä¾¡**:

$$
f_{\text{goal}}(\text{SPM}, \theta_{\text{goal}}) = \sum_{\theta=1}^{N_\theta} w_{\theta}(\theta_{\text{goal}}) \cdot \sum_r \text{SPM}_{\text{occ}}[r, \theta]
$$

ã“ã“ã§ï¼š
$$
w_{\theta}(\theta_{\text{goal}}) = \cos(\theta - \theta_{\text{goal}})
$$

- $\theta_{\text{goal}}$: çŠ¬ã‹ã‚‰è¦‹ãŸç›®æ¨™æ–¹å‘ã®è§’åº¦ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
- **æ„å‘³**: ç›®æ¨™æ–¹å‘ã«è¿‘ã„ã»ã©é«˜ã„é‡ã¿
- **æœ€å°åŒ–**: ç¾ŠãŒç›®æ¨™ã¨åå¯¾å´ã«ã„ã‚‹çŠ¶æ…‹ã‚’é¿ã‘ã‚‹
- **çŠ¬ã®æœ€é©ä½ç½®**: ç¾Šã®å¾Œæ–¹ï¼ˆç¾Šã¨ç›®æ¨™ã®é–“ã«ä½ç½®ã—ãªã„ï¼‰

**Shepherdingç‰¹åŒ–ç‰ˆ**:

çŠ¬ã¯ç¾Šã®**å¾Œæ–¹ã‹ã‚‰æŠ¼ã™**ä½ç½®ã‚’å–ã‚‹ã¹ãï¼š

$$
f_{\text{goal}}^{\text{push}}(\text{SPM}, \theta_{\text{goal}}) = \sum_{\theta} \left| \text{angle\_diff}(\theta, \theta_{\text{goal}} + \pi) \right| \cdot \sum_r \text{SPM}_{\text{occ}}[r, \theta]
$$

- ç¾ŠãŒ $\theta_{\text{goal}} + \pi$ æ–¹å‘ï¼ˆç›®æ¨™ã®åå¯¾å´ï¼‰ã«ã„ã‚‹ã“ã¨ã‚’æ¨å¥¨
- ã“ã‚Œã«ã‚ˆã‚Šã€çŠ¬ãŒç¾Šã‚’å¾Œã‚ã‹ã‚‰æŠ¼ã™å½¢ã«ãªã‚‹

#### 3. Radial Distributionï¼ˆè·é›¢åˆ†å¸ƒï¼‰

**Occupancyã®å‹•å¾„æ–¹å‘åˆ†å¸ƒ**ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰:

$$
f_{\text{radial}}(\text{SPM}, r_{\text{prefer}}) = \sum_{r=1}^{N_r} (r - r_{\text{prefer}})^2 \cdot \sum_{\theta} \text{SPM}_{\text{occ}}[r, \theta]
$$

- $r_{\text{prefer}}$: æœ›ã¾ã—ã„è·é›¢ãƒ“ãƒ³ï¼ˆä¾‹: bin 3-4 = mid-rangeï¼‰
- **æ„å‘³**: ç¾ŠãŒé©åˆ‡ãªè·é›¢ã«ã„ã‚‹ã‹
- **è¿‘ã™ãã‚‹** ($r$ å°) â†’ ç¾ŠãŒé€ƒã’ã¦æ•£ã‚‰ã°ã‚‹
- **é ã™ãã‚‹** ($r$ å¤§) â†’ åˆ¶å¾¡ãŒåŠ¹ã‹ãªã„

#### 4. Velocity Coherenceï¼ˆé€Ÿåº¦ã®æ•´åˆæ€§ï¼‰

**RadialãŠã‚ˆã³Tangentialãƒãƒ£ãƒãƒ«ã®åˆ©ç”¨**ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰:

$$
f_{\text{velocity}}(\text{SPM}) = \text{Var}_{\theta} \left[ \sum_r \text{SPM}_{\text{radi}}[r, \theta] \right] + \text{Var}_{\theta} \left[ \sum_r \text{SPM}_{\text{tang}}[r, \theta] \right]
$$

- **æ„å‘³**: ç¾Šã®é€Ÿåº¦æ–¹å‘ã®çµ±ä¸€æ€§
- **ä½åˆ†æ•£** â†’ ç¾ŠãŒåŒã˜æ–¹å‘ã«ç§»å‹•ï¼ˆè‰¯ã„ï¼‰
- **é«˜åˆ†æ•£** â†’ ç¾ŠãŒãƒãƒ©ãƒãƒ©ã®æ–¹å‘ã«ç§»å‹•ï¼ˆæ‚ªã„ï¼‰

### 3.4 Shepherding ã«ãŠã‘ã‚‹ Social Valueï¼ˆSPMãƒ™ãƒ¼ã‚¹ï¼‰

Shepherdingã‚¿ã‚¹ã‚¯ã§ã¯ã€ä»¥ä¸‹ã®2ã¤ã®ç›®æ¨™ã‚’çµ±åˆï¼š

$$
\boxed{M_{\text{social}}^{\text{shepherd}}(a) = \lambda_{\text{compact}} \cdot f_{\text{compact}}^{\text{angular}}(\text{SPM}(a)) + \lambda_{\text{goal}} \cdot f_{\text{goal}}^{\text{push}}(\text{SPM}(a), \theta_{\text{goal}})}
$$

**SPMãƒ™ãƒ¼ã‚¹ã®è¡Œå‹•ä¾å­˜æ€§**:

```
çŠ¬ã®è¡Œå‹• a
  â†“
çŠ¬ã®å°†æ¥ä½ç½®ãƒ»é€Ÿåº¦ (p_future, v_future)
  â†“
SPMäºˆæ¸¬ SPM(a) = predict_spm(p_future, v_future, sheep_list)
  |
  |--- Occupancyãƒãƒ£ãƒãƒ« â†’ f_compact(è§’åº¦ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼)
  |--- Occupancyãƒãƒ£ãƒãƒ« + ç›®æ¨™è§’åº¦ â†’ f_goal(å¾Œæ–¹æŠ¼ã—å‡ºã—)
  â†“
M_social(a)
```

**å…·ä½“çš„ãªå®šå¼åŒ–**:

1. **Angular Compactness**ï¼ˆè§’åº¦ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã§è©•ä¾¡ï¼‰:

$$
f_{\text{compact}}^{\text{angular}}(\text{SPM}) = -\sum_{\theta=1}^{N_\theta} P(\theta) \log P(\theta)
$$

$$
P(\theta) = \frac{\sum_{r} \text{SPM}_{\text{occ}}[r, \theta]}{\sum_{r,\theta'} \text{SPM}_{\text{occ}}[r, \theta']}
$$

- **æœ€å°åŒ–**: ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ãŒä½ã„ = ç¾ŠãŒç‰¹å®šæ–¹å‘ã«é›†ä¸­ = è‰¯ã„
- **SPMåˆ©ç‚¹**: GRUäºˆæ¸¬ã‹ã‚‰ç›´æ¥è¨ˆç®—å¯èƒ½

2. **Goal Pushing**ï¼ˆå¾Œæ–¹ã‹ã‚‰ã®æŠ¼ã—å‡ºã—ï¼‰:

$$
f_{\text{goal}}^{\text{push}}(\text{SPM}, \theta_{\text{goal}}) = -\sum_{\theta} \cos(\theta - (\theta_{\text{goal}} + \pi)) \cdot O(\theta)
$$

ã“ã“ã§ï¼š
$$
O(\theta) = \sum_r \text{SPM}_{\text{occ}}[r, \theta]
$$

- $\theta_{\text{goal}}$: çŠ¬ã‹ã‚‰è¦‹ãŸç›®æ¨™æ–¹å‘ï¼ˆSPMåº§æ¨™ç³»ï¼‰
- $\theta_{\text{goal}} + \pi$: ç›®æ¨™ã®åå¯¾å´ï¼ˆçŠ¬ãŒä½ç½®ã™ã¹ãæ–¹å‘ï¼‰
- **æœ€å°åŒ–**: ç¾Šã‚’ç›®æ¨™ã¨åå¯¾å´ã«é…ç½® â†’ çŠ¬ãŒå¾Œæ–¹ã‹ã‚‰æŠ¼ã™å½¢

**é‡ã¿ã®ä¾‹**:
- $\lambda_{\text{compact}} = 1.0$: é›†ç´„ã®é‡è¦åº¦
- $\lambda_{\text{goal}} = 0.5$: ç›®æ¨™åˆ°é”ã®é‡è¦åº¦

**é‡ã¿ã®èª¿æ•´ã«ã‚ˆã‚‹æˆ¦ç•¥å¤‰åŒ–**:

| Phase | $\lambda_{\text{compact}}$ | $\lambda_{\text{goal}}$ | æˆ¦ç•¥ |
|-------|---------------------------|------------------------|------|
| Early | 2.0 | 0.5 | ã¾ãšé›†ç´„ï¼ˆCollectingï¼‰ |
| Middle | 1.0 | 1.0 | é›†ç´„ã—ãªãŒã‚‰èª˜å° |
| Late | 0.5 | 2.0 | ç›®æ¨™åˆ°é”å„ªå…ˆï¼ˆDrivingï¼‰ |

**StrÃ¶mbomã¨ã®æ¯”è¼ƒ**:
- **StrÃ¶mbom**: å›ºå®šé–¾å€¤ã§Collecting â†” Drivingåˆ‡ã‚Šæ›¿ãˆ
- **EPH + Social Value**: é€£ç¶šçš„ãªé‡ã¿èª¿æ•´ã§æ»‘ã‚‰ã‹ãªé·ç§»

---

## 4. Haze ã¨ã®é–¢ä¿‚

### 4.1 Haze ã®å½¹å‰²ã®å¾©ç¿’

**Haze Tensor** $\mathcal{H}(r, \theta, c)$ ã¯ã€SPMï¼ˆSaliency Polar Mapï¼‰ä¸Šã®**ç²¾åº¦å¤‰èª¿å ´**ã§ã‚ã‚‹ï¼š

$$
\Pi(r, \theta, c) = \Pi_{\text{base}}(r, \theta, c) \cdot (1 - h(r, \theta, c))^{\gamma}
$$

- $\Pi$: Precisionï¼ˆç²¾åº¦ï¼‰
- $h \in [0, 1]$: Hazeå€¤ï¼ˆé«˜ã„ã»ã©ä½ç²¾åº¦ï¼‰
- $\gamma > 0$: æ„Ÿåº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

**Hazeã®åŠ¹æœ**:
- **é«˜Haze** â†’ ä½ç²¾åº¦ â†’ æƒ…å ±ã‚’ä¿¡é ¼ã—ãªã„ â†’ Epistemic ValueãŒå°ã•ã„
- **ä½Haze** â†’ é«˜ç²¾åº¦ â†’ æƒ…å ±ã‚’ä¿¡é ¼ã™ã‚‹ â†’ Epistemic ValueãŒå¤§ãã„

### 4.2 Epistemic ã¨ Pragmatic ã®åˆ†é›¢

**é‡è¦ãªåŸå‰‡**:

> **Hazeã¯ Epistemic Term ã®ã¿ã‚’å¤‰èª¿ã—ã€Pragmatic Termï¼ˆSocial Valueï¼‰ã¯ç›´æ¥å¤‰èª¿ã—ãªã„**

**ç†ç”±**:
1. **Epistemicï¼ˆèªè­˜çš„ä¾¡å€¤ï¼‰**: çŸ¥è¦šã®ä¸ç¢ºå®Ÿæ€§ã«é–¢ã™ã‚‹é …
   - Hazeã¯ã€ŒçŸ¥è¦šã®ä¿¡é ¼åº¦ã€ã‚’å¤‰èª¿
   - ã€Œã“ã®æƒ…å ±ã‚’ã©ã‚Œãã‚‰ã„ä¿¡ã˜ã‚‹ã‹ã€ã‚’èª¿æ•´
   - SPMç©ºé–“ã§å‹•ä½œ

2. **Pragmaticï¼ˆå®Ÿç”¨çš„ä¾¡å€¤ï¼‰**: ç›®æ¨™é”æˆã«é–¢ã™ã‚‹é …
   - ç›®æ¨™çŠ¶æ…‹ã¯çŸ¥è¦šä¸ç¢ºå®Ÿæ€§ã¨ã¯ç‹¬ç«‹
   - ã€Œä½•ã‚’é”æˆã—ãŸã„ã‹ã€ã¯çŸ¥è¦šç²¾åº¦ã¨ã¯ç„¡é–¢ä¿‚
   - å®Ÿç©ºé–“ã§ã®çŠ¶æ…‹è©•ä¾¡

**æ•°å¼ã§ã®è¡¨ç¾**:

$$
G(a) = \underbrace{F_{\text{percept}}(a, \mathcal{H})}_{\text{Hazeã§ç›´æ¥å¤‰èª¿}} + \underbrace{M_{\text{social}}(a)}_{\text{Hazeã§ç›´æ¥å¤‰èª¿ã•ã‚Œãªã„}}
$$

**æ³¨æ„**: Social Valueã¯è¡Œå‹•$a$ã‚’é€šã˜ã¦é–“æ¥çš„ã«Hazeã®å½±éŸ¿ã‚’å—ã‘ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚
- HazeãŒè¡Œå‹•é¸æŠã«å½±éŸ¿ â†’ è¡Œå‹•ãŒå¤‰åŒ– â†’ Social Valueã‚‚å¤‰åŒ–
- ã—ã‹ã—ã€ã“ã‚Œã¯é–“æ¥çš„ãªå½±éŸ¿ã§ã‚ã‚Šã€ç›´æ¥çš„ãªå¤‰èª¿ã§ã¯ãªã„

### 4.3 ç›¸è£œçš„ãªå½¹å‰²

Hazeã¨Social Valueã¯ç›¸è£œçš„ã«æ©Ÿèƒ½ã™ã‚‹ï¼š

| é … | Haze | Social Value |
|----|------|--------------|
| **å¤‰èª¿å¯¾è±¡** | Epistemic Value | â€” |
| **åˆ¶å¾¡å†…å®¹** | çŸ¥è¦šã®ç²¾åº¦ | è¡Œå‹•ã®å‹•æ©Ÿ |
| **æ©Ÿèƒ½** | è¡çªå›é¿ã®å¼·åº¦èª¿æ•´ | é›†ç´„ãƒ»èª˜å°ã®ç›®æ¨™è¨­å®š |
| **æ™‚é–“ã‚¹ã‚±ãƒ¼ãƒ«** | é€Ÿã„ï¼ˆæ¯ã‚¹ãƒ†ãƒƒãƒ—ï¼‰ | é…ã„ï¼ˆæˆ¦ç•¥ãƒ¬ãƒ™ãƒ«ï¼‰ |
| **ç©ºé–“ç¯„å›²** | å±€æ‰€çš„ï¼ˆSPMã®ç‰¹å®šbinï¼‰ | å¤§åŸŸçš„ï¼ˆå…¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼‰ |

**å…·ä½“ä¾‹ï¼ˆShepherdingï¼‰**:

```
ã€Collecting Phaseã€‘
- Social Value: Î»_compact = 2.0, Î»_goal = 0.5
  â†’ ã€Œç¾Šã‚’é›†ã‚ã‚ï¼ã€ã¨ã„ã†å‹•æ©ŸãŒå¼·ã„

- Haze: ç¾Šæ–¹å‘ã«ä½Hazeã€ãã®ä»–ã¯é«˜Haze
  â†’ ç¾Šã«æ³¨æ„ã‚’é›†ä¸­ã€ä»–ã¯æ°—ã«ã—ãªã„

çµæœ: çŠ¬ãŒç¾Šã‚’ç©æ¥µçš„ã«é›†ã‚ã‚‹


ã€Driving Phaseã€‘
- Social Value: Î»_compact = 0.5, Î»_goal = 2.0
  â†’ ã€Œç›®æ¨™ã«å‘ã‹ãˆï¼ã€ã¨ã„ã†å‹•æ©ŸãŒå¼·ã„

- Haze: å‰æ–¹ã«ä½Hazeã€å¾Œæ–¹ã«é«˜Haze
  â†’ é€²è¡Œæ–¹å‘ã‚’æ³¨è¦–ã€å¾Œã‚ã¯æ°—ã«ã—ãªã„

çµæœ: çŠ¬ãŒç¾Šã‚’ç›®æ¨™ã«èª˜å°
```

### 4.4 Compactness ä¸å¤‰æ€§ã®è§£æ±º

**Phase 3ã®ç™ºè¦‹**:
> åç™ºåŠ›ã®ã¿ã®ã‚·ã‚¹ãƒ†ãƒ ã§ã¯ã€Hazeæ“ä½œã¯agent dispersionï¼ˆåˆ†æ•£åº¦ï¼‰ã‚’å¤‰æ›´ã§ããªã„

**ç†è«–çš„èª¬æ˜**:
- Hazeã¯ã€Œæ—¢å­˜ã®é§†å‹•åŠ›ã€ã‚’å¤‰èª¿ã™ã‚‹ã ã‘
- åç™ºåŠ›ã®ã¿ â†’ Hazeã¯åç™ºã®å¼·ã•ã‚’å¤‰ãˆã‚‹ã ã‘
- å¼•åŠ›ãŒãªã„ â†’ é›†ç´„ã™ã‚‹åŠ›ãŒãªã„

**Social Valueã«ã‚ˆã‚‹è§£æ±º**:
- Social Value = æ–°ã—ã„é§†å‹•åŠ›ï¼ˆé›†ç´„ã¸ã®å‹•æ©Ÿï¼‰
- Haze = ãã®é§†å‹•åŠ›ã®ç©ºé–“çš„å¤‰èª¿

**çµ±åˆåŠ¹æœ**:

$$
\text{Total Drive} = \underbrace{\text{Repulsion}}_{\text{Hazeã§å¤‰èª¿}} + \underbrace{\text{Social Attraction}}_{\text{æ–°ã—ã„é§†å‹•åŠ›}}
$$

Hazeã¯ Social Attractionã®ç©ºé–“åˆ†å¸ƒã‚’å¤‰èª¿ã—ã€åŠ¹æœçš„ãªé›†ç´„ã‚’å®Ÿç¾ï¼š
- ç¾Šã«è¿‘ã„æ–¹å‘: ä½Haze â†’ Social AttractionãŒå¼·ãåƒã â†’ ç©æ¥µçš„ã«é›†ã‚ã‚‹
- ç¾Šã‹ã‚‰é ã„æ–¹å‘: é«˜Haze â†’ Social AttractionãŒå¼±ã¾ã‚‹ â†’ åŠ¹ç‡çš„

---

## 5. å®Ÿè£…æ–¹æ³•

### 5.1 EPH Controller ã¸ã®çµ±åˆï¼ˆSPMãƒ™ãƒ¼ã‚¹å®Ÿè£…ï¼‰

**é‡è¦ãªåŸå‰‡**:
1. Social Valueã¯è¡Œå‹•$a$ã«ã‚ˆã‚‹**å°†æ¥ã®SPMäºˆæ¸¬**ã‹ã‚‰è¨ˆç®—
2. ç¾Šã®ä½ç½®ã‚’ç›´æ¥ä½¿ã‚ãšã€SPMã®Occupancyãƒãƒ£ãƒãƒ«ã‹ã‚‰è¨ˆç®—
3. GRUäºˆæ¸¬å™¨ã‚’ä½¿ç”¨ï¼ˆæ—¢å­˜ã®Phase 2å®Ÿè£…ã‚’æ´»ç”¨ï¼‰

```julia
"""
EFE with Social Value and Haze Modulation (SPM-based Implementation)
"""
function compute_efe_with_social_value(
    action::Vector{Float64},
    dog::Agent,
    sheep_list::Vector{SheepAgent},
    goal_position::Vector{Float64},
    params::EPHParams,
    gru_predictor::GRUPredictor  # Phase 2ã§å®Ÿè£…æ¸ˆã¿
)
    # === 1. Predict future state from action ===
    dog_pos_future = dog.position + action * params.dt
    dog_vel_future = action

    # === 2. Predict future SPM using GRU ===
    # Option A: Use GRU predictor (preferred for trained models)
    spm_predicted = predict_spm_gru(
        gru_predictor,
        dog.spm_history,  # Past SPMs
        action,
        params
    )

    # Option B: Use 1-step forward simulation (for baseline)
    # spm_predicted = compute_spm_at_future_position(
    #     dog_pos_future,
    #     dog_vel_future,
    #     sheep_list,
    #     params
    # )

    # === 3. Epistemic Term (Haze-modulated) ===
    F_percept = compute_surprise_cost_with_haze(
        spm_predicted,
        dog.haze_matrix,
        params
    )

    # === 4. Pragmatic Term: Social Value (SPM-based) ===
    # 4.1 Compute goal direction in SPM coordinates
    goal_vec = goal_position - dog_pos_future
    Î¸_goal = atan(goal_vec[2], goal_vec[1]) - atan(dog_vel_future[2], dog_vel_future[1])
    Î¸_goal_idx = angle_to_spm_index(Î¸_goal, params.NÎ¸)

    # 4.2 Angular Compactness (from Occupancy channel)
    M_compact = compute_angular_compactness(spm_predicted, params)

    # 4.3 Goal Pushing (from Occupancy + goal direction)
    M_goal = compute_goal_pushing(spm_predicted, Î¸_goal_idx, params)

    # 4.4 Combined Social Value
    M_social = params.Î»_compact * M_compact + params.Î»_goal * M_goal

    # === 5. Total EFE ===
    G = F_percept + M_social

    return G
end

"""
Angular Compactness from SPM Occupancy channel
Low entropy = compact (good), high entropy = dispersed (bad)
"""
function compute_angular_compactness(
    spm::Array{Float64, 3},
    params::EPHParams
)
    # Extract occupancy channel (channel 1)
    occ = spm[1, :, :]  # Shape: (Nr, NÎ¸)

    # Sum over radial bins to get angular distribution
    O_Î¸ = sum(occ, dims=1)  # Shape: (1, NÎ¸)
    O_Î¸ = vec(O_Î¸)  # Shape: (NÎ¸,)

    # Normalize to probability distribution
    total = sum(O_Î¸)
    if total < 1e-6
        # No sheep visible â†’ neutral cost
        return 0.0
    end

    P_Î¸ = O_Î¸ / total

    # Compute entropy
    H = 0.0
    for p in P_Î¸
        if p > 1e-10
            H -= p * log(p)
        end
    end

    # Return entropy (minimize for compactness)
    return H
end

"""
Goal Pushing: encourage sheep to be in direction opposite to goal
(so dog can push from behind)
"""
function compute_goal_pushing(
    spm::Array{Float64, 3},
    Î¸_goal_idx::Int,
    params::EPHParams
)
    # Extract occupancy channel
    occ = spm[1, :, :]  # Shape: (Nr, NÎ¸)

    # Sum over radial bins
    O_Î¸ = sum(occ, dims=1)  # Shape: (1, NÎ¸)
    O_Î¸ = vec(O_Î¸)  # Shape: (NÎ¸,)

    # Compute target direction: opposite to goal (dog should be behind sheep)
    Î¸_target = mod1(Î¸_goal_idx + params.NÎ¸ Ã· 2, params.NÎ¸)

    # Angular cost: prefer sheep in target direction
    cost = 0.0
    for Î¸ in 1:params.NÎ¸
        # Angular distance from target
        Î”Î¸ = min(abs(Î¸ - Î¸_target), params.NÎ¸ - abs(Î¸ - Î¸_target))

        # Weight based on angular distance
        w = cos(2Ï€ * Î”Î¸ / params.NÎ¸)

        # Penalize if sheep NOT in target direction
        # (minimize â†’ wants high occupancy at Î¸_target)
        cost -= w * O_Î¸[Î¸]
    end

    return cost
end
```

**SPMãƒ™ãƒ¼ã‚¹å®Ÿè£…ã®åˆ©ç‚¹**:

1. **å‹¾é…è¨ˆç®—ã®åŠ¹ç‡æ€§**:
   - SPMäºˆæ¸¬ã¯æ—¢ã«å¾®åˆ†å¯èƒ½ï¼ˆGRU/Zygoteã§å®Ÿè£…æ¸ˆã¿ï¼‰
   - `action` â†’ `spm_predicted` â†’ `M_social` ã®å…¨çµŒè·¯ãŒå¾®åˆ†å¯èƒ½
   - $\nabla_a M_{\text{social}}$ ãŒè‡ªå‹•çš„ã«è¨ˆç®—ã•ã‚Œã‚‹

2. **çŸ¥è¦šçš„ä¸€è²«æ€§**:
   - çŠ¬ã¯è‡ªèº«ã®SPMï¼ˆçŸ¥è¦šï¼‰ã®ã¿ã‹ã‚‰æ„æ€æ±ºå®š
   - ç¾Šã®æ­£ç¢ºãªä½ç½®ã‚’çŸ¥ã‚‰ãªãã¦ã‚‚æ©Ÿèƒ½
   - ã‚ˆã‚Šç”Ÿç‰©å­¦çš„ã«å¦¥å½“

3. **Phase 2ã¨ã®çµ±åˆ**:
   - GRUäºˆæ¸¬å™¨ã‚’ãã®ã¾ã¾åˆ©ç”¨å¯èƒ½
   - è¿½åŠ ã®äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ãŒä¸è¦
   - æ—¢å­˜ã®ã‚¤ãƒ³ãƒ•ãƒ©ã‚’æœ€å¤§æ´»ç”¨

4. **è¨ˆç®—åŠ¹ç‡**:
   - ç¾Šã®å€‹åˆ¥ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŒä¸è¦ï¼ˆ1-step forward baselineã‚’é™¤ãï¼‰
   - O(N_r Ã— N_Î¸) ã®è¨ˆç®—é‡ï¼ˆç¾Šã®æ•°ã«ä¾å­˜ã—ãªã„ï¼‰

### 5.2 Surprise Cost ã®è¨ˆç®—ï¼ˆHazeå¤‰èª¿ã‚ã‚Šï¼‰

```julia
"""
Compute surprise cost with haze modulation
"""
function compute_surprise_cost_with_haze(
    spm::Array{Float64, 3},
    haze_matrix::Matrix{Float64},
    params::EPHParams
)
    F = 0.0
    Nr, NÎ¸, Nc = size(spm)

    for r in 1:Nr, Î¸ in 1:NÎ¸, c in 1:Nc
        # Base precision
        Ï€_base = params.Î _base[r, Î¸, c]

        # Haze modulation
        h = haze_matrix[r, Î¸]
        Ï€_modulated = Ï€_base * (1.0 - h)^params.Î³

        # Precision-weighted squared error
        # (ä»®ã« temporal prediction errorã¨ã—ã¦)
        prediction_error = spm[r, Î¸, c]^2
        F += Ï€_modulated * prediction_error
    end

    return F
end
```

### 5.3 å‹•çš„ãªé‡ã¿èª¿æ•´

```julia
"""
Adaptive weight adjustment based on task phase
"""
function adjust_social_value_weights(
    agent::Agent,
    other_agents::Vector{Agent},
    goal_position::Vector{Float64},
    params::EPHParams
)
    # Compute current compactness
    com = compute_center_of_mass(other_agents)
    C = mean([norm(a.position - com)^2 for a in other_agents])

    # Compute distance to goal
    D_goal = norm(com - goal_position)

    # Adaptive strategy
    if C > params.C_threshold_high
        # Highly dispersed â†’ Focus on collecting
        Î»_compact = 2.0
        Î»_goal = 0.5
    elseif C < params.C_threshold_low
        # Already compact â†’ Focus on driving
        Î»_compact = 0.5
        Î»_goal = 2.0
    else
        # Balanced
        Î»_compact = 1.0
        Î»_goal = 1.0
    end

    return (Î»_compact, Î»_goal)
end
```

### 5.4 Zygote ã«ã‚ˆã‚‹å‹¾é…é™ä¸‹

```julia
"""
Action selection via gradient descent on EFE
"""
function select_action_with_social_value(
    agent::Agent,
    other_agents::Vector{Agent},
    goal_position::Vector{Float64},
    params::EPHParams
)
    # Initialize with previous velocity
    a = copy(agent.velocity)

    # Gradient descent
    for iter in 1:params.n_gradient_steps
        # Compute gradient via automatic differentiation
        grad = gradient(a -> compute_efe_with_social_value(
            a, agent, other_agents, goal_position, params
        ), a)[1]

        # Update action
        a = a - params.Î· * grad

        # Clip to max speed
        if norm(a) > params.max_speed
            a = params.max_speed * normalize(a)
        end
    end

    return a
end
```

---

## 6. ç†è«–çš„æ€§è³ª

### 6.1 Social Value ã®åæŸæ€§

**å‘½é¡Œ1**: Social ValueãŒå‡¸é–¢æ•°ã§ã‚ã‚Œã°ã€å‹¾é…é™ä¸‹ã¯ã‚°ãƒ­ãƒ¼ãƒãƒ«æœ€å°ã«åæŸã™ã‚‹ã€‚

**è¨¼æ˜ã‚¹ã‚±ãƒƒãƒ**:
1. Compactnessé … $f_{\text{compact}}(s) = \sum_i ||\mathbf{p}_i - \mathbf{p}_{\text{COM}}||^2$ ã¯å‡¸
2. Goal Distanceé … $f_{\text{goal}}(s) = ||\mathbf{p}_{\text{COM}} - \mathbf{p}_{\text{goal}}||^2$ ã¯å‡¸
3. å‡¸é–¢æ•°ã®éè² ç·šå½¢çµåˆã¯å‡¸
4. å‡¸é–¢æ•°ã®å‹¾é…é™ä¸‹ã¯ã‚°ãƒ­ãƒ¼ãƒãƒ«æœ€å°ã«åæŸï¼ˆå­¦ç¿’ç‡ $\eta$ ãŒé©åˆ‡ãªã‚‰ï¼‰

**å®Ÿè£…ä¸Šã®æ³¨æ„**: Epistemicé …ã¯ä¸€èˆ¬ã«éå‡¸ã€‚åæŸã¯local minimumã¾ã§ã€‚

### 6.2 Haze ã¨ Social Value ã®é–¢ä¿‚

**å‘½é¡Œ2**: Hazeå¤‰èª¿ã¯Epistemicé …ã‚’**ç›´æ¥å¤‰èª¿**ã™ã‚‹ãŒã€Social Valueé …ã¯**ç›´æ¥å¤‰èª¿ã—ãªã„**ã€‚

**ç†ç”±**:

1. **æ•°å¼ä¸Šã®ç‹¬ç«‹æ€§**:
   $$
   M_{\text{social}}(a) = f(\text{SPM}(a), \theta_{\text{goal}})
   $$
   ã“ã®å¼ã«Haze $\mathcal{H}$ ã¯**æ˜ç¤ºçš„ã«ç¾ã‚Œãªã„**ã€‚

   (æ³¨: SPMãƒ™ãƒ¼ã‚¹å®šå¼åŒ–ã§ã¯ã€SPMäºˆæ¸¬ã‹ã‚‰ç‰¹å¾´é–¢æ•°ã‚’è¨ˆç®—)

2. **é–“æ¥çš„ãªå½±éŸ¿ã¯å­˜åœ¨**:
   - HazeãŒè¡Œå‹•é¸æŠã«å½±éŸ¿ â†’ è¡Œå‹•$a$ãŒå¤‰åŒ– â†’ Social Valueã‚‚å¤‰åŒ–
   - ã—ã‹ã—ã€ã“ã‚Œã¯$M_{\text{social}}$ã®å®šç¾©è‡ªä½“ãŒå¤‰ã‚ã‚‹ã‚ã‘ã§ã¯ãªã„

**å½¢å¼çš„è¡¨ç¾**:

$$
\frac{\partial M_{\text{social}}(a)}{\partial \mathcal{H}} = \frac{\partial M_{\text{social}}}{\partial a} \cdot \frac{\partial a}{\partial \mathcal{H}}
$$

- ç¬¬1é …: Social Valueã®è¡Œå‹•æ„Ÿåº¦ï¼ˆéã‚¼ãƒ­ï¼‰
- ç¬¬2é …: Hazeã«ã‚ˆã‚‹è¡Œå‹•å¤‰åŒ–ï¼ˆEpistemicé …ã‚’é€šã˜ã¦éã‚¼ãƒ­ï¼‰
- **ç©ã¯éã‚¼ãƒ­**ï¼ˆé–“æ¥çš„å½±éŸ¿ã‚ã‚Šï¼‰

ã—ã‹ã—ã€å®šç¾©ä¸Šã®ç›´æ¥ä¾å­˜ã¯ãªã„ï¼š

$$
\frac{\partial M_{\text{social}}(a, \mathcal{H})}{\partial \mathcal{H}} \bigg|_{a=\text{const}} = 0
$$

**å®Ÿè£…ä¸Šã®å«æ„**:
- Hazeã¯çŸ¥è¦šç²¾åº¦ã®è¨­è¨ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
- Social Valueã¯ç›®æ¨™çŠ¶æ…‹ã®è¨­è¨ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
- ä¸¡è€…ã¯ç•°ãªã‚‹å´é¢ã‚’åˆ¶å¾¡ã™ã‚‹ãŒã€è¡Œå‹•é¸æŠã‚’é€šã˜ã¦ç›¸äº’ä½œç”¨ã™ã‚‹

### 6.3 Compactness ä¸å¤‰æ€§ã®å½¢å¼çš„è¨¼æ˜

**å®šç†**: åç™ºåŠ›ã®ã¿ã®ã‚·ã‚¹ãƒ†ãƒ  $F_{\text{repulsion}} = -\sum_{i \neq j} \nabla V_{\text{rep}}(||\mathbf{p}_i - \mathbf{p}_j||)$ ã«ãŠã„ã¦ã€Hazeå¤‰èª¿ $\mathcal{H}(r, \theta)$ ã¯å¹³è¡¡çŠ¶æ…‹ã®Compactness $C^*$ ã‚’å¤‰æ›´ã—ãªã„ã€‚

**è¨¼æ˜**:

1. å¹³è¡¡çŠ¶æ…‹: $\sum_j F_{ij}^{\text{rep}} = 0 \quad \forall i$

2. Hazeå¤‰èª¿: $F_{ij}^{\text{rep}} \to w_{ij}(\mathcal{H}) \cdot F_{ij}^{\text{rep}}$ ã“ã“ã§ $w_{ij} > 0$

3. æ–°ã—ã„å¹³è¡¡: $\sum_j w_{ij} F_{ij}^{\text{rep}} = 0$

4. ã‚¹ã‚±ãƒ¼ãƒ«ä¸å¤‰æ€§: $F_{ij}^{\text{rep}} \propto ||\mathbf{p}_i - \mathbf{p}_j||^{-n}$ ãªã‚‰ã€$w_{ij}$ ã®å¤‰åŒ–ã¯ç›¸å¯¾ä½ç½®ã®ã‚¹ã‚±ãƒ¼ãƒ«å¤‰åŒ–ã®ã¿

5. Compactness $C = \text{Var}[\mathbf{p}_i]$ ã¯ã‚¹ã‚±ãƒ¼ãƒ«ä¸å¤‰ï¼ˆç›¸å¯¾ä½ç½®ãŒä¿å­˜ã•ã‚Œã‚‹ãŸã‚ï¼‰

**çµè«–**: åç™ºã®ã¿ã§ã¯çµ¶å¯¾çš„ãªCompactnessã¯åˆ¶å¾¡ä¸å¯ã€‚å¼•åŠ›ï¼ˆSocial Valueï¼‰ãŒå¿…é ˆã€‚

---

## 7. Shepherding ã¸ã®å¿œç”¨

### 7.1 å•é¡Œè¨­å®š

**ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ**:
- **çŠ¬ï¼ˆDogï¼‰**: EPHåˆ¶å¾¡ã€ç›®æ¨™ã¯ç¾Šã‚’é›†ã‚ã¦ç›®æ¨™åœ°ç‚¹ã«èª˜å°
- **ç¾Šï¼ˆSheepï¼‰**: BOIDSè¡Œå‹• + çŠ¬ã‹ã‚‰ã®é€ƒèµ°åå¿œ

**ã‚¿ã‚¹ã‚¯**:
1. æ•£ã‚‰ã°ã£ãŸç¾Šã‚’é›†ç´„ï¼ˆCollectingï¼‰
2. é›†ç´„ã—ãŸç¾Šã‚’ç›®æ¨™åœ°ç‚¹ã«èª˜å°ï¼ˆDrivingï¼‰

**è©•ä¾¡æŒ‡æ¨™**:
- Success Rate: ç¾ŠãŒç›®æ¨™é ˜åŸŸã«åˆ°é”ã—ãŸã‹
- Time to Goal: èª˜å°å®Œäº†ã¾ã§ã®æ™‚é–“
- Compactness: ç¾Šã®å¯†é›†åº¦ï¼ˆã‚¿ã‚¹ã‚¯ä¸­ã®å¹³å‡ï¼‰
- Dog Efficiency: çŠ¬ã®ç§»å‹•è·é›¢

### 7.2 EPH Shepherding ã®å®Ÿè£…

> [!NOTE]
> **æœ€æ–°ã®å®Ÿè£…æ–¹æ³•**: ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯å®Ÿè£…ã®å…¨ä½“æ§‹é€ ã‚’ç¤ºã™ã‚¹ã‚±ãƒ«ãƒˆãƒ³ã§ã™ã€‚
> **Social Valueã®SPMãƒ™ãƒ¼ã‚¹å®Ÿè£…**ã«ã¤ã„ã¦ã¯**Section 5.1**ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚
> Section 5.1ã§ã¯ã€GRUäºˆæ¸¬å™¨ã‚’ä½¿ã£ãŸæœ€æ–°ã®SPMãƒ™ãƒ¼ã‚¹ç‰¹å¾´é–¢æ•°ãŒå®šç¾©ã•ã‚Œã¦ã„ã¾ã™ã€‚

**å®Œå…¨ãªå®Ÿè£…ä¾‹ï¼ˆæ§‹é€ ã®ã¿ã€è©³ç´°ã¯Section 5.1å‚ç…§ï¼‰**:

```julia
# ========================================
# EPH Shepherding Agent
# ========================================

mutable struct DogAgent <: Agent
    position::Vector{Float64}
    velocity::Vector{Float64}
    spm::Array{Float64, 3}
    haze_self::Float64
    haze_matrix::Matrix{Float64}
    Î»_compact::Float64
    Î»_goal::Float64
end

function update_dog_agent!(
    dog::DogAgent,
    sheep_list::Vector{SheepAgent},
    goal_position::Vector{Float64},
    params::EPHParams
)
    # 1. Update SPM (perception of current state)
    dog.spm = compute_spm(dog, sheep_list, params)

    # 2. Compute self-haze (adaptive)
    occupancy = sum(dog.spm[1, :, :])  # Channel 1 = Occupancy
    dog.haze_self = compute_self_haze(occupancy, params)

    # 3. Adjust Social Value weights (adaptive)
    (dog.Î»_compact, dog.Î»_goal) = adjust_social_value_weights(
        dog, sheep_list, goal_position, params
    )

    # 4. Compute haze matrix (spatial modulation)
    dog.haze_matrix = compute_haze_for_shepherding(
        dog, sheep_list, goal_position, params
    )

    # 5. Select action via EFE minimization with gradient descent
    # IMPORTANT: This uses forward prediction of sheep reactions
    action = select_action_shepherding(
        dog, sheep_list, goal_position, params
    )

    # 6. Update position and velocity
    dog.velocity = 0.7 * action + 0.3 * dog.velocity  # Smoothing
    dog.position += dog.velocity * params.dt

    # Toroidal wrap
    dog.position = mod.(dog.position, params.world_size)
end

# ========================================
# Action Selection with Gradient Descent
# ========================================

function select_action_shepherding(
    dog::DogAgent,
    sheep_list::Vector{SheepAgent},
    goal_position::Vector{Float64},
    params::EPHParams
)
    # Initialize with previous velocity
    a = copy(dog.velocity)

    # Gradient descent on EFE
    for iter in 1:params.n_gradient_steps
        # Compute gradient via automatic differentiation
        # This automatically computes âˆ‡_a M_social through forward prediction
        grad = gradient(a -> compute_efe_with_social_value(
            a, dog, sheep_list, goal_position, params
        ), a)[1]

        # Gradient descent step
        a = a - params.Î· * grad

        # Clip to max speed
        if norm(a) > params.max_speed
            a = params.max_speed * normalize(a)
        end
    end

    return a
end

# ========================================
# Haze Strategy for Shepherding
# ========================================

function compute_haze_for_shepherding(
    dog::DogAgent,
    sheep_list::Vector{SheepAgent},
    goal_position::Vector{Float64},
    params::EPHParams
)
    h_matrix = ones(Float64, params.Nr, params.NÎ¸)

    # Strategy 1: Low haze toward sheep (focus on sheep)
    com = compute_center_of_mass(sheep_list)
    sheep_direction_vec = com - dog.position
    sheep_angle = atan(sheep_direction_vec[2], sheep_direction_vec[1])

    # Convert to SPM angular index
    Î¸_sheep = angle_to_theta_index(sheep_angle, params.NÎ¸)

    # Low haze in Â±30Â° around sheep direction
    for dÎ¸ in -2:2
        Î¸_idx = mod1(Î¸_sheep + dÎ¸, params.NÎ¸)
        h_matrix[:, Î¸_idx] *= 0.5  # High precision toward sheep
    end

    # Strategy 2: Mid-distance high haze (avoid over-planning)
    h_matrix[3:5, :] *= 2.0  # Bins 3-5 = mid-range

    # Strategy 3: Combine with self-haze
    h_matrix = max.(h_matrix, dog.haze_self)

    # Clamp to [0, 1]
    clamp!(h_matrix, 0.0, 1.0)

    return h_matrix
end

# ========================================
# Sheep BOIDS Model
# ========================================

mutable struct SheepAgent
    position::Vector{Float64}
    velocity::Vector{Float64}
    boids_weights::Vector{Float64}  # [w_sep, w_ali, w_coh]
end

function update_sheep_agent!(
    sheep::SheepAgent,
    sheep_list::Vector{SheepAgent},
    dog_list::Vector{DogAgent},
    params::SheepParams
)
    # BOIDS forces
    f_sep = compute_separation(sheep, sheep_list, params)
    f_ali = compute_alignment(sheep, sheep_list, params)
    f_coh = compute_cohesion(sheep, sheep_list, params)

    # Flee from dogs
    f_flee = compute_flee_from_dogs(sheep, dog_list, params)

    # Weighted combination
    w = sheep.boids_weights
    f_total = w[1]*f_sep + w[2]*f_ali + w[3]*f_coh + f_flee

    # Update velocity and position
    sheep.velocity += f_total * params.dt

    # Speed limit
    if norm(sheep.velocity) > params.max_speed
        sheep.velocity = params.max_speed * normalize(sheep.velocity)
    end

    sheep.position += sheep.velocity * params.dt

    # Toroidal wrap
    sheep.position = mod.(sheep.position, params.world_size)
end

function compute_flee_from_dogs(
    sheep::SheepAgent,
    dog_list::Vector{DogAgent},
    params::SheepParams
)
    f_flee = zeros(2)

    for dog in dog_list
        d_vec = sheep.position - dog.position
        d = norm(d_vec)

        # Exponential decay
        if d < params.flee_range
            flee_strength = params.k_flee * exp(-d / params.r_fear)
            f_flee += flee_strength * normalize(d_vec)
        end
    end

    return f_flee
end
```

### 7.3 StrÃ¶mbom ã¨ã®æ¯”è¼ƒ

**StrÃ¶mbom (2014) ã®2ãƒ•ã‚§ãƒ¼ã‚ºã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ **:

```julia
function strombom_update!(dog::DogAgent, sheep_list, goal, params)
    com = compute_center_of_mass(sheep_list)
    max_dist = maximum([norm(s.position - com) for s in sheep_list])

    if max_dist > params.collecting_threshold
        # Collecting: gather stray sheep
        farthest = argmax([norm(s.position - com) for s in sheep_list])
        target = sheep_list[farthest].position +
                 params.offset * normalize(com - sheep_list[farthest].position)
    else
        # Driving: push toward goal
        target = com - params.driving_dist * normalize(goal - com)
    end

    # Simple movement toward target
    dog.velocity = params.dog_speed * normalize(target - dog.position)
    dog.position += dog.velocity * params.dt
end
```

**æ¯”è¼ƒè¡¨**:

| å´é¢ | StrÃ¶mbom | EPH + Social Value |
|------|----------|-------------------|
| **ç†è«–åŸºç›¤** | ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ | Active Inference + FEP |
| **ãƒ•ã‚§ãƒ¼ã‚ºåˆ‡ã‚Šæ›¿ãˆ** | å›ºå®šé–¾å€¤ï¼ˆmax_dist > thresholdï¼‰ | é€£ç¶šçš„ï¼ˆÎ»_compact/Î»_goalå‹•çš„èª¿æ•´ï¼‰ |
| **Hazeåˆ©ç”¨** | ãªã— | ã‚ã‚Šï¼ˆçŸ¥è¦šç²¾åº¦ã‚’ç©ºé–“çš„ã«å¤‰èª¿ï¼‰ |
| **é©å¿œæ€§** | é™çš„ç’°å¢ƒã‚’ä»®å®š | æ™‚å¤‰BOIDSç’°å¢ƒã«å¯¾å¿œ |
| **ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£** | 1çŠ¬å°‚ç”¨ | è¤‡æ•°çŠ¬ã®å”èª¿ãŒç†è«–çš„ã«å¯èƒ½ |
| **å­¦ç¿’å¯èƒ½æ€§** | ãƒ«ãƒ¼ãƒ«å›ºå®š | GRU Haze Policyã§æœ€é©åŒ–å¯èƒ½ |
| **è¨ˆç®—è¤‡é›‘åº¦** | O(N) per step | O(N Ã— G) (G=å‹¾é…ã‚¹ãƒ†ãƒƒãƒ—æ•°) |

---

## 8. å®Ÿé¨“è¨­è¨ˆ

### 8.1 è©•ä¾¡å®Ÿé¨“ã®æ§‹æˆ

**ç‹¬ç«‹å¤‰æ•°**:
1. **åˆ¶å¾¡æ‰‹æ³•**: EPH, StrÃ¶mbom, Random
2. **BOIDSæ™‚å¤‰æ€§**: Static, Dynamic (3-phase)
3. **ç¾Šã®æ•°**: 10, 20, 50
4. **çŠ¬ã®æ•°**: 1, 2

**å¾“å±å¤‰æ•°**:
1. Success Rate
2. Time to Goal
3. Compactness (mean over trajectory)
4. Dog Efficiency (total distance traveled)
5. **Adaptation Index** = Performance_Dynamic / Performance_Static

**çµ±è¨ˆçš„æ¤œå®š**:
- å„æ¡ä»¶ã§30å›å®Ÿè¡Œï¼ˆseeds: 42-71ï¼‰
- å¯¾å¿œã®ãªã„tæ¤œå®šï¼ˆEPH vs StrÃ¶mbomï¼‰
- åŠ¹æœé‡ Cohen's d
- æœ‰æ„æ°´æº– Î± = 0.05

### 8.2 Ablation Study

**ç›®çš„**: å„è¦ç´ ã®å¯„ä¸ã‚’æ˜ç¢ºåŒ–

| Condition | Social Value | Haze Modulation | äºˆæƒ³çµæœ |
|-----------|--------------|-----------------|---------|
| Baseline | âŒ | âŒ | å¤±æ•—ï¼ˆé›†ç´„ä¸å¯ï¼‰ |
| +Social Value | âœ… | âŒ | éƒ¨åˆ†çš„æˆåŠŸï¼ˆéåŠ¹ç‡ï¼‰ |
| +Haze (uniform) | âŒ | âœ… | å¤±æ•—ï¼ˆå‹•æ©Ÿãªã—ï¼‰ |
| **Full EPH** | âœ… | âœ… | æˆåŠŸï¼ˆåŠ¹ç‡çš„ï¼‰ |

**æ¤œè¨¼é …ç›®**:
1. Social Value ãªã— â†’ Compactnessä¸å¤‰æ€§ã«ã‚ˆã‚Šé›†ç´„å¤±æ•—
2. Haze ãªã— â†’ é›†ç´„å¯èƒ½ã ãŒéåŠ¹ç‡ï¼ˆéå‰°ãªè¡çªå›é¿ï¼‰
3. Full EPH â†’ é›†ç´„ + åŠ¹ç‡çš„èª˜å°

---

## 9. Discussion

### 9.1 ç†è«–çš„æ„ç¾©

**Active Inferenceã¸ã®è²¢çŒ®**:
1. **Prior Preferenceã®å…·ä½“ä¾‹**: Social Valueã¯ã€Œæœ›ã¾ã—ã„ç¤¾ä¼šçš„çŠ¶æ…‹ã€ã‚’æ˜ç¤ºçš„ã«å®šå¼åŒ–
2. **Epistemic-Pragmaticåˆ†é›¢ã®å®Ÿè¨¼**: Hazeã¯èªè­˜ã€Social Valueã¯å‹•æ©Ÿã¨ã—ã¦ç‹¬ç«‹å‹•ä½œ
3. **Multi-agent Active Inference**: å€‹ä½“ãƒ¬ãƒ™ãƒ«ã®EFEæœ€å°åŒ– â†’ é›†å›£ãƒ¬ãƒ™ãƒ«ã®å”èª¿è¡Œå‹•

**Compactnessä¸å¤‰æ€§ã®ç†è«–çš„ä¾¡å€¤**:
- Negative Result ã®å»ºè¨­çš„æ´»ç”¨
- Hazeã®æœ¬è³ªï¼ˆå¤‰èª¿å™¨ã§ã‚ã‚Šç”Ÿæˆå™¨ã§ã¯ãªã„ï¼‰ã®è§£æ˜
- æ–°ã—ã„è¨­è¨ˆåŸå‰‡ã®ç¢ºç«‹

### 9.2 å®Ÿè£…ä¸Šã®çŸ¥è¦‹

**æˆåŠŸã®ãŸã‚ã®3è¦ç´ **:
1. **Social Value**: ã‚¿ã‚¹ã‚¯å›ºæœ‰ã®ç›®æ¨™ã‚’å®šå¼åŒ–
2. **Haze Modulation**: çŸ¥è¦šç²¾åº¦ã‚’ç©ºé–“çš„ã«èª¿æ•´
3. **é©å¿œçš„é‡ã¿**: ç’°å¢ƒå¤‰åŒ–ã«å¿œã˜ã¦ $\lambda$ ã‚’å‹•çš„èª¿æ•´

**é¿ã‘ã‚‹ã¹ãè½ã¨ã—ç©´**:
- Social Value ã‚’éåº¦ã«è¤‡é›‘åŒ–ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ãª2é …ã§ååˆ†ï¼‰
- Hazeã®éå‰°å¤‰èª¿ï¼ˆ5Ã—ä»¥ä¸Šã¯ä¸å®‰å®šï¼‰
- å›ºå®šé‡ã¿ï¼ˆé©å¿œæ€§ã®å–ªå¤±ï¼‰

### 9.3 ä»Šå¾Œã®ç ”ç©¶æ–¹å‘

**Short-term** (Phase 4):
- BOIDSç¾Š + EPHçŠ¬ã®å®Ÿè£…ã¨æ¤œè¨¼
- StrÃ¶mbomã¨ã®å®šé‡æ¯”è¼ƒ
- æ™‚å¤‰BOIDSç’°å¢ƒã§ã®é©å¿œæ€§å®Ÿè¨¼

**Mid-term**:
- GRU Haze Policyã®å­¦ç¿’ï¼ˆMeta-RLï¼‰
- è¤‡æ•°çŠ¬ã®å”èª¿Shepherding
- å®Ÿãƒ­ãƒœãƒƒãƒˆæ¤œè¨¼ï¼ˆTurtlebot3ï¼‰

**Long-term**:
- éšå±¤çš„Active Inferenceï¼ˆå€‹ä½“â†”ç¾¤ã‚Œï¼‰
- ä¸€èˆ¬åŒ–ã•ã‚ŒãŸSocial Valueç†è«–
- ä»–ã‚¿ã‚¹ã‚¯ã¸ã®å±•é–‹ï¼ˆFlocking, Formation Controlï¼‰

---

## 10. å‚è€ƒæ–‡çŒ®

### Free Energy Principle & Active Inference

1. **Friston, K. J. (2010).** The free-energy principle: a unified brain theory? *Nature Reviews Neuroscience*, 11(2), 127-138.
   DOI: [10.1038/nrn2787](https://doi.org/10.1038/nrn2787)
   **ãƒã‚¤ãƒ³ãƒˆ**: FEPã®çµ±ä¸€çš„ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€‚VFEã®å®šç¾©ã¨ç”Ÿç‰©å­¦çš„æ„ç¾©ã€‚

2. **Friston, K. J., Daunizeau, J., & Kiebel, S. J. (2009).** Reinforcement learning or active inference? *PLoS ONE*, 4(7), e6421.
   DOI: [10.1371/journal.pone.0006421](https://doi.org/10.1371/journal.pone.0006421)
   **ãƒã‚¤ãƒ³ãƒˆ**: Active Inferenceã¨RLã®é–¢ä¿‚ã€‚EFEã®å°å‡ºã€‚

3. **Friston, K., Rigoli, F., Ognibene, D., Mathys, C., Fitzgerald, T., & Pezzulo, G. (2015).** Active inference and epistemic value. *Cognitive Neuroscience*, 6(4), 187-214.
   DOI: [10.1080/17588928.2015.1020053](https://doi.org/10.1080/17588928.2015.1020053)
   **ãƒã‚¤ãƒ³ãƒˆ**: Epistemic Valueã¨Pragmatic Valueã®åˆ†è§£ã€‚æƒ…å ±ç²å¾—è¡Œå‹•ã®ç†è«–ã€‚

4. **Parr, T., & Friston, K. J. (2019).** Generalised free energy and active inference. *Biological Cybernetics*, 113(5-6), 495-513.
   DOI: [10.1007/s00422-019-00805-w](https://doi.org/10.1007/s00422-019-00805-w)
   **ãƒã‚¤ãƒ³ãƒˆ**: Generalized Free Energyã®æ•°å­¦çš„å³å¯†åŒ–ã€‚

### Shepherding & Collective Behavior

5. **StrÃ¶mbom, D., Mann, R. P., Wilson, A. M., Hailes, S., Morton, A. J., Sumpter, D. J., & King, A. J. (2014).** Solving the shepherding problem: heuristics for herding autonomous, interacting agents. *Journal of The Royal Society Interface*, 11(100), 20140719.
   DOI: [10.1098/rsif.2014.0719](https://doi.org/10.1098/rsif.2014.0719)
   **ãƒã‚¤ãƒ³ãƒˆ**: 2ãƒ•ã‚§ãƒ¼ã‚ºShepherdingã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã€‚å®Ÿé¨“çš„æ¤œè¨¼ã‚ã‚Šã€‚

6. **Couzin, I. D., Krause, J., James, R., Ruxton, G. D., & Franks, N. R. (2002).** Collective memory and spatial sorting in animal groups. *Journal of Theoretical Biology*, 218(1), 1-11.
   DOI: [10.1006/jtbi.2002.3065](https://doi.org/10.1006/jtbi.2002.3065)
   **ãƒã‚¤ãƒ³ãƒˆ**: Informed individualsã«ã‚ˆã‚‹ç¾¤ã‚Œèª˜å°ã€‚Shepherdingã®ç”Ÿç‰©å­¦çš„åŸºç›¤ã€‚

7. **Reynolds, C. W. (1987).** Flocks, herds and schools: A distributed behavioral model. *ACM SIGGRAPH Computer Graphics*, 21(4), 25-34.
   DOI: [10.1145/37402.37406](https://doi.org/10.1145/37402.37406)
   **ãƒã‚¤ãƒ³ãƒˆ**: BOIDSãƒ¢ãƒ‡ãƒ«ã®ææ¡ˆã€‚Separation, Alignment, Cohesionã®3ãƒ«ãƒ¼ãƒ«ã€‚

### Multi-agent Active Inference

8. **Ã‡atal, O., Verbelen, T., Nauta, J., De Boom, C., & Dhoedt, B. (2020).** Learning perception and planning with deep active inference. *IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)*, 3952-3956.
   DOI: [10.1109/ICASSP40776.2020.9054364](https://doi.org/10.1109/ICASSP40776.2020.9054364)
   **ãƒã‚¤ãƒ³ãƒˆ**: ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«ã‚ˆã‚‹Active Inferenceå®Ÿè£…ã€‚

9. **Sajid, N., Ball, P. J., Parr, T., & Friston, K. J. (2021).** Active inference: Demystified and compared. *Neural Computation*, 33(3), 674-712.
   DOI: [10.1162/neco_a_01357](https://doi.org/10.1162/neco_a_01357)
   **ãƒã‚¤ãƒ³ãƒˆ**: Active Inferenceã¨RL/MDPã®æ•°å­¦çš„é–¢ä¿‚ã®æ•´ç†ã€‚

### Precision & Attention

10. **Feldman, H., & Friston, K. J. (2010).** Attention, uncertainty, and free-energy. *Frontiers in Human Neuroscience*, 4, 215.
    DOI: [10.3389/fnhum.2010.00215](https://doi.org/10.3389/fnhum.2010.00215)
    **ãƒã‚¤ãƒ³ãƒˆ**: Precision weightingã¨æ³¨æ„æ©Ÿæ§‹ã®é–¢ä¿‚ã€‚Hazeã®ç†è«–çš„åŸºç›¤ã€‚

---

## Appendix: æ•°å­¦çš„è£œè¶³

### A.1 KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã®æ€§è³ª

$$
D_{KL}[q(s) || p(s)] = \int q(s) \log \frac{q(s)}{p(s)} ds
$$

**æ€§è³ª**:
1. éè² æ€§: $D_{KL}[q || p] \geq 0$
2. ç­‰å·æˆç«‹: $D_{KL}[q || p] = 0 \Leftrightarrow q = p$ (a.e.)
3. éå¯¾ç§°: $D_{KL}[q || p] \neq D_{KL}[p || q]$ (ä¸€èˆ¬ã«)

### A.2 å¤‰åˆ†è‡ªç”±ã‚¨ãƒãƒ«ã‚®ãƒ¼ã®å°å‡º

ãƒ™ã‚¤ã‚ºã®å®šç†ã‹ã‚‰:

$$
p(s|o) = \frac{p(o|s)p(s)}{p(o)}
$$

å¯¾æ•°ã‚’å–ã‚‹:

$$
\log p(s|o) = \log p(o|s) + \log p(s) - \log p(o)
$$

ä¸¡è¾ºã« $q(s)$ ã‚’ã‹ã‘ã¦ç©åˆ†:

$$
\int q(s) \log p(s|o) ds = \int q(s) [\log p(o|s) + \log p(s)] ds - \log p(o)
$$

å·¦è¾ºã‚’å¤‰å½¢:

$$
\int q(s) \log p(s|o) ds = -D_{KL}[q(s) || p(s|o)]
$$

å³è¾ºã‚’æ•´ç†:

$$
-D_{KL}[q(s) || p(s|o)] = \mathbb{E}_{q(s)}[\log p(o,s)] - \mathbb{E}_{q(s)}[\log q(s)] - \log p(o)
$$

ç§»é …:

$$
\log p(o) = \underbrace{\mathbb{E}_{q(s)}[\log p(o,s)] - \mathbb{E}_{q(s)}[\log q(s)]}_{-F} + D_{KL}[q(s) || p(s|o)]
$$

$D_{KL} \geq 0$ ã‚ˆã‚Š:

$$
\log p(o) \geq -F
$$

ã“ã‚ŒãŒVFEã®ä¸‹ç•Œï¼ˆEvidence Lower Bound, ELBOï¼‰ã®æ„å‘³ã€‚

### A.3 å‹¾é…ã®è¨ˆç®—ï¼ˆZygoteã«ã‚ˆã‚‹è‡ªå‹•å¾®åˆ†ï¼‰

EFEæœ€å°åŒ–:

$$
a^* = \arg\min_a G(a)
$$

å‹¾é…é™ä¸‹:

$$
a_{k+1} = a_k - \eta \nabla_a G(a_k)
$$

Zygoteã®ä½¿ç”¨ä¾‹:

```julia
using Zygote

function objective(a)
    return compute_efe_with_social_value(a, agent, others, goal, params)
end

# å‹¾é…è¨ˆç®—
grad = gradient(objective, a)[1]

# æ›´æ–°
a_new = a - Î· * grad
```

---

**Document Status**: âœ… Complete (Revised)
**Version**: 1.2
**Last Updated**: 2025-11-25

**Revision History**:
- **v1.2** (2025-11-25): SPM-based feature functions
  - Social Value computed from SPM Occupancy channel (not raw positions)
  - Added: Angular Compactness (entropy), Goal Pushing (cosine weighting)
  - Integrates with GRU predictor (Phase 2)
  - More biologically plausible (perceptual grounding)
- **v1.1** (2025-11-25): Action-dependency correction
  - $M_{\text{social}}(a)$ not $M_{\text{social}}(s)$
  - Ensures $\nabla_a M_{\text{social}} \neq 0$ for gradient descent
- **v1.0** (2025-11-25): Initial version

**Key Features**:
- âœ… SPM-based perceptual grounding
- âœ… Action-dependent formulation
- âœ… Haze-modulated Epistemic term
- âœ… Integration with GRU predictor
- âœ… Shepherding task application

**Author**: Hiroshi Igarashi (AI-DLC, Tokyo Denki University)
**License**: Internal Research Document
