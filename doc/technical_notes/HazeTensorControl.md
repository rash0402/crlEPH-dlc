---
title: "Haze Tensor Control: A General Framework for Swarm Behavioral Guidance"
subtitle: "ç²¾åº¦å¤‰èª¿ãƒ†ãƒ³ã‚½ãƒ«ã«ã‚ˆã‚‹ç¾¤è¡Œå‹•åˆ¶å¾¡ã®æ±ç”¨ç†è«–"
type: Technical_Note
status: ğŸŸ¢ Active
version: 1.0
date_created: 2025-11-25
date_modified: 2025-11-25
author: "Hiroshi Igarashi"
institution: "Tokyo Denki University"
keywords:
  - Haze Tensor
  - Precision Modulation
  - Swarm Control
  - Active Inference
  - Behavioral Guidance
  - Stigmergy
---

# Haze Tensor Control: A General Framework for Swarm Behavioral Guidance

> [!ABSTRACT]
> **Purpose**: æœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã€Haze Tensor ã‚’ç”¨ã„ãŸç¾¤è¡Œå‹•åˆ¶å¾¡ã®æ±ç”¨çš„ç†è«–ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’æç¤ºã™ã‚‹ã€‚EPHã¯Shepherdingå°‚ç”¨ã§ã¯ãªãã€Exploration, Foraging, Pursuit-Evasion, Formation Controlç­‰ã€å¤šæ§˜ãªã‚¿ã‚¹ã‚¯ã«é©ç”¨å¯èƒ½ãª**æ±ç”¨ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ**ã§ã‚ã‚‹ã€‚Hazeãƒ†ãƒ³ã‚½ãƒ«ã®ç©ºé–“çš„é…ç½®ã‚’æ“ä½œã™ã‚‹ã“ã¨ã§ã€æ˜ç¤ºçš„ãªé€šä¿¡ã‚„ä¸­å¤®åˆ¶å¾¡ãªã—ã«ã€ç¾¤ã‚Œã®å”èª¿è¡Œå‹•ã‚’èª˜å°ã™ã‚‹åŸç†ã‚’æ˜ã‚‰ã‹ã«ã™ã‚‹ã€‚

## 0. Executive Summary

### 0.1 Core Concept

**Haze Tensor** $\mathcal{H}(r, \theta, c)$ ã¯ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®çŸ¥è¦šç©ºé–“ï¼ˆSaliency Polar Mapï¼‰ä¸Šã§å®šç¾©ã•ã‚Œã‚‹ **ç²¾åº¦å¤‰èª¿å ´ï¼ˆPrecision Modulation Fieldï¼‰** ã§ã‚ã‚‹ã€‚Hazeã¯ä»¥ä¸‹ã®3ã¤ã®åˆ¶å¾¡ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã§å®Ÿç¾ã•ã‚Œã‚‹ï¼š

1. **Self-Hazing** (è‡ªå¾‹çš„èª¿æ•´): ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå†…éƒ¨çŠ¶æ…‹ã«åŸºã¥ãå‹•çš„èª¿æ•´
2. **Environmental Hazing** (Stigmergy): ç’°å¢ƒã«åŸ‹ã‚è¾¼ã¾ã‚ŒãŸåˆ¶å¾¡ä¿¡å·
3. **Engineered Hazing** (å¤–éƒ¨åˆ¶å¾¡): è¨­è¨ˆè€…ã«ã‚ˆã‚‹æ˜ç¤ºçš„ãªHazeé…ç½®

ã“ã‚Œã‚‰3ã¤ã®Hazeã‚½ãƒ¼ã‚¹ã‚’çµ±åˆã™ã‚‹ã“ã¨ã§ã€**ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ã‹ã¤ãƒ­ãƒã‚¹ãƒˆãªåˆ†æ•£åˆ¶å¾¡**ãŒå®Ÿç¾ã•ã‚Œã‚‹ã€‚

### 0.2 Key Principles

#### Principle 1: Haze is a Modulator, Not a Generator
Hazeã¯**è¡Œå‹•ã®æ ¹æœ¬çš„å‹•æ©Ÿï¼ˆå¼•åŠ›ãƒ»åç™ºãƒ»ç›®æ¨™ï¼‰ã‚’ç”Ÿæˆã—ãªã„**ã€‚æ—¢å­˜ã®è¡Œå‹•é§†å‹•åŠ›ï¼ˆActive Inferenceã®Pragmatic/Epistemic termsï¼‰ã‚’**é¸æŠçš„ã«å¤‰èª¿**ã™ã‚‹ã€‚

**Example**:
- å¼•åŠ›ãŒãªã„ç³»: Hazeæ“ä½œ â†’ å¯†é›†åº¦å¤‰åŒ–ãªã— âŒ
- å¼•åŠ›ãŒã‚ã‚‹ç³»: Hazeæ“ä½œ â†’ å¼•åŠ›ã®é¸æŠçš„æŠ‘åˆ¶/å¼·åŒ– âœ…

#### Principle 2: Spatial Selectivity is Essential
ãƒãƒ£ãƒ³ãƒãƒ«æ¬¡å…ƒï¼ˆOccupancy, Radial, Tangentialï¼‰ã®é¸æŠçš„Hazeã¯ä¸ååˆ†ã€‚**ç©ºé–“æ¬¡å…ƒï¼ˆè·é›¢ãƒ»è§’åº¦ï¼‰**ã§ã®é¸æŠæ€§ãŒæœ‰åŠ¹ã€‚

**Validated strategies**:
- Distance-selective (Mid-range haze) â†’ +4% exploration efficiency
- Asymmetric angular haze â†’ Limited robustness (seed-dependent)

#### Principle 3: Multi-Scale Control Hierarchy
Hazeã¯è¤‡æ•°ã®ã‚¹ã‚±ãƒ¼ãƒ«ã§æ©Ÿèƒ½ï¼š
- **Microscopic**: å€‹ä½“ã®çŸ¥è¦šãƒã‚¤ã‚¢ã‚¹ï¼ˆSelf-Hazeï¼‰
- **Mesoscopic**: å±€æ‰€çš„ãªç¾¤ã‚Œãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ï¼ˆEnvironmental Hazeï¼‰
- **Macroscopic**: ç¾¤ã‚Œå…¨ä½“ã®å‰µç™ºãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆCollective behaviorï¼‰

---

## 1. Theoretical Foundation

### 1.1 Precision-Weighted Active Inference

Active Inferenceã§ã¯ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ **Expected Free Energy (EFE)** ã‚’æœ€å°åŒ–ï¼š

$$
\boxed{G(a) = \mathbb{E}_{q(o|a)}[\ln q(s|o,a) - \ln p(s, o|\tilde{o})] - H[q(o|a)]}
$$

Simplified form (EPH implementation):

$$
G(a) = \underbrace{F_{percept}(a, \mathcal{H})}_{\text{Pragmatic}} + \underbrace{\beta \cdot H[q(s|a, \mathcal{H})]}_{\text{Epistemic}} + \underbrace{\lambda \cdot M_{meta}(a)}_{\text{Task-specific}}
$$

**Haze Tensor** $\mathcal{H}$ modulates **Precision Matrix** $\boldsymbol{\Pi}$:

$$
\Pi(r, \theta, c; \mathcal{H}) = \Pi_{base}(r, \theta, c) \cdot \underbrace{\exp(-\alpha \cdot h(r, \theta, c))}_{\text{Exponential decay}}
$$

where:
- $h \in [0, \infty)$: Haze value (higher â†’ lower precision)
- $\alpha \geq 1$: Decay rate (controls haze sensitivity)
- $\Pi_{base}$: Base precision (distance-dependent, Gaussian-based)

**Key property**: Low precision â†’ High covariance â†’ High entropy â†’ Exploration

### 1.2 Haze as Cognitive Filter

Hazeã¯ **æ³¨æ„é…åˆ†ï¼ˆAttention Allocationï¼‰** ã®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã¨ã—ã¦æ©Ÿèƒ½ï¼š

```
High Haze Region â†’ Low Precision â†’ Low Gradient Contribution
                  â†’ "Ignore this direction"
                  â†’ Reduce computational/behavioral cost

Low Haze Region â†’ High Precision â†’ High Gradient Contribution
                â†’ "Focus on this direction"
                â†’ Accurate collision avoidance
```

**Cognitive resource allocation**:
$$
\text{Effective compute} = \sum_{r,\theta} \Pi(r,\theta; \mathcal{H}) \cdot \text{ProcessingCost}(r,\theta)
$$

High haze â†’ Reduce effective compute â†’ Faster decision-making (at the cost of local accuracy)

### 1.3 Three Sources of Haze

#### 1.3.1 Self-Haze (Autonomic)

Computed from agent's own perceptual state (SPM):

$$
h_{self}(t) = h_{max} \cdot \sigma\left( -\alpha (\Omega(t) - \Omega_{threshold}) \right)
$$

where $\Omega(t) = \sum_{r,\theta} \text{SPM}[1, r, \theta]$ (total occupancy)

**Interpretation**:
- Low occupancy ($\Omega < \Omega_{threshold}$) â†’ High self-haze â†’ Exploration
- High occupancy ($\Omega > \Omega_{threshold}$) â†’ Low self-haze â†’ Exploitation

**Implementation**: `src_julia/control/SelfHaze.jl::compute_self_haze()`

#### 1.3.2 Environmental Haze (Stigmergy)

Embedded in 2D spatial grid $\mathcal{H}_{env}(x, y)$:

```julia
# Haze deposition by agent
function deposit_haze!(env, agent, haze_type, strength)
    if haze_type == :lubricant
        env.haze_grid[agent.position] -= strength  # Low haze â†’ High precision
    elseif haze_type == :repellent
        env.haze_grid[agent.position] += strength  # High haze â†’ Low precision
    end
end

# Haze decay over time
env.haze_grid .*= decay_rate  # e.g., 0.99
```

**Two types**:
- **Lubricant Haze** (Low haze): Increase precision â†’ Encourage following
- **Repellent Haze** (High haze): Decrease precision â†’ Discourage revisiting

**Analogy to pheromones**:
| Aspect | ACO Pheromone | EPH Haze |
|--------|---------------|----------|
| **Nature** | Positive value (reward) | Precision modulation (ä¿¡é ¼åº¦) |
| **Effect** | Attract agents | Bias attention |
| **Dynamics** | Reinforcement | Stigmergic information |
| **Interpretation** | "Good path" | "Reliable/Unreliable direction" |

#### 1.3.3 Engineered Haze (External Control)

Explicitly designed haze tensor for specific control objectives:

**Example: Distance-Selective Haze**
```julia
# Increase haze at mid-distance to suppress over-planning
mid_range = 3:max(3, Nr-2)
for r in mid_range
    for Î¸ in 1:NÎ¸
        h_matrix[r, Î¸] *= 5.0  # Amplify haze
    end
end
```

**Effect**: Agents ignore mid-range obstacles â†’ More direct paths â†’ Better coverage

**Example: Asymmetric Angular Haze**
```julia
# Increase haze in left hemisphere
for Î¸_idx in 1:NÎ¸
    Î¸ = compute_angle(Î¸_idx)
    if Î¸ >= 0.0  # Left half
        h_matrix[:, Î¸_idx] *= 2.0
    end
end
```

**Effect** (context-dependent): Break symmetry â†’ Consistent turn bias âš ï¸ (Low robustness)

### 1.4 Haze Composition

Total haze at agent $i$ at position $(x, y)$:

$$
\mathcal{H}_{total}^{(i)}(r, \theta) = \max\left( h_{self}^{(i)}(r, \theta), \mathcal{H}_{env}(x + r\cos\theta, y + r\sin\theta), \mathcal{H}_{eng}(r, \theta) \right)
$$

**Composition operator**: $\max$ (pessimistic - highest uncertainty wins)

Alternative operators:
- $\text{mean}$: Average uncertainty
- $\text{product}$: Multiplicative composition (all sources must agree)

**Design choice**: $\max$ operator ensures **conservative behavior** (if any source indicates uncertainty, trust is reduced)

---

## 2. Task-Specific Applications

### 2.1 General Application Template

Forä»»æ„ã®swarm taskã«é©ç”¨å¯èƒ½ãªæ±ç”¨ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼š

#### Step 1: Identify Behavioral Drives
Determine task-specific Pragmatic Value $M_{meta}(a)$:

**Examples**:
- **Exploration**: $M_{meta} = (v - v_{target})^2$ (maintain speed)
- **Foraging**: $M_{meta} = ||\mathbf{p}_{agent} - \mathbf{p}_{resource}||^2$ (minimize distance to resource)
- **Shepherding**: $M_{meta} = ||\mathbf{p}_{dog} - \mathbf{p}_{sheep\_COM}||^2$ (Collecting phase)
- **Formation**: $M_{meta} = ||\mathbf{p}_{agent} - \mathbf{p}_{formation}||^2$ (maintain formation position)

#### Step 2: Design Haze Strategy
Choose haze modulation to enhance task performance:

**Exploration** â†’ Mid-distance haze (suppress over-planning)
**Foraging** â†’ High haze away from resource direction (focus attention forward)
**Shepherding** â†’ Low haze toward sheep (maintain awareness)
**Formation** â†’ High haze perpendicular to formation axis (ignore irrelevant directions)

#### Step 3: Validate Control Effect
Measure task-specific metrics:

| Task | Key Metrics |
|------|-------------|
| **Exploration** | Coverage rate, Time to 80%, Novelty rate |
| **Foraging** | Resource collection rate, Travel efficiency |
| **Shepherding** | Sheep compactness, Herding success rate, Time to goal |
| **Formation** | Formation error (MSE from desired positions), Stability |

### 2.2 Application 1: Exploration (âœ… Validated)

**Objective**: Maximize coverage of unknown environment

**Behavioral drives**:
- $F_{percept}$: Collision avoidance (inherent)
- $\beta \cdot H[q]$: Epistemic exploration (inherent)
- $M_{meta}$: Speed maintenance (avoidåœæ­¢)

**Haze strategy**: Distance-selective haze (Mid-range)

```julia
# Production configuration (from experimental validation)
mid_range = 3:max(3, Nr-2)
h_matrix[mid_range, :] *= 5.0
```

**Performance**:
- Coverage @500 steps: **93.2%** (+4.0% vs Baseline)
- Collision reduction: -2.7%
- Control cost: +82% (acceptable trade-off)

**Reference**: [Haze Tensor Effect Report](../experimental_reports/haze_tensor_effect.md#321-coverage-maximization)

### 2.3 Application 2: Shepherding (ğŸ”§ Proposed)

**Objective**: Guide sheep flock to target location

**Behavioral drives**:
- $F_{percept}$: Collision avoidance
- $M_{collect}$: Minimize distance to sheep COM (Collecting phase)
- $M_{drive}$: Minimize sheep COM to goal distance (Driving phase)
- $S_{social}$: Dog-dog coordination (maintain spacing)

**Haze strategy**: Context-aware modulation

##### Collecting Phase (Sheep dispersed)
```julia
# Low haze toward sheep â†’ Maintain awareness
for Î¸_idx in 1:NÎ¸
    Î¸ = angle_to_sheep_COM(agent, Î¸_idx)
    if abs(Î¸) < Ï€/4  # Front cone toward sheep
        h_matrix[:, Î¸_idx] *= 0.5  # Decrease haze â†’ Increase precision
    end
end
```

**Effect**: Dog focuses attention on sheep â†’ Efficient approach

##### Driving Phase (Sheep compact)
```julia
# High haze behind sheep â†’ Ignore rear obstacles
for Î¸_idx in 1:NÎ¸
    Î¸ = angle_from_sheep_COM_to_goal(agent, Î¸_idx)
    if abs(Î¸) > 3Ï€/4  # Rear cone
        h_matrix[:, Î¸_idx] *= 3.0  # Increase haze â†’ Decrease precision
    end
end
```

**Effect**: Dog maintains pressure from behind without over-reacting

**Expected performance** (hypothesis):
- Sheep compactness: >10Ã— baseline (with Social Value term)
- Time to goal: -20% vs StrÃ¶mbom (2014)
- Robustness to sheep behavior changes: +30%

### 2.4 Application 3: Foraging (ğŸ”¬ Speculative)

**Objective**: Collect resources from environment, return to nest

**Behavioral drives**:
- $M_{search}$: Exploration (when not carrying resource)
- $M_{collect}$: Minimize distance to resource (when resource detected)
- $M_{return}$: Minimize distance to nest (when carrying resource)

**Haze strategy**: Phase-dependent modulation

##### Search Phase
```julia
# Repellent haze at previously visited locations (Environmental Haze)
deposit_haze!(env, agent, :repellent, 0.5)
```

**Effect**: Avoid redundant search â†’ Improve coverage

##### Return Phase
```julia
# Lubricant haze trail toward nest (Environmental Haze)
deposit_haze!(env, agent, :lubricant, 0.3)
```

**Effect**: Other agents follow trail â†’ Collective path formation

**Expected emergent behavior**: Ant-like trail formation without explicit communication

### 2.5 Application 4: Pursuit-Evasion (ğŸ”¬ Speculative)

**Objective**: Pursuer agents capture evader agents

**Behavioral drives** (Pursuer):
- $M_{pursuit}$: Minimize distance to nearest evader
- $F_{percept}$: Avoid collisions with teammates

**Haze strategy**: Forward-focused attention

```julia
# High haze in lateral and rear directions
for Î¸_idx in 1:NÎ¸
    Î¸ = compute_angle(Î¸_idx)
    if abs(Î¸) > Ï€/3  # Lateral/rear
        h_matrix[:, Î¸_idx] *= 4.0
    end
end
```

**Effect**: Pursuer focuses on forward direction â†’ Faster reaction to evader movements

**Behavioral drives** (Evader):
- $M_{evade}$: Maximize distance from nearest pursuer
- $F_{percept}$: Avoid obstacles

**Haze strategy**: Rear-focused attention

```julia
# Low haze in rear direction (high precision on pursuers)
for Î¸_idx in 1:NÎ¸
    Î¸ = compute_angle(Î¸_idx)
    if abs(Î¸ - Ï€) < Ï€/4  # Rear cone
        h_matrix[:, Î¸_idx] *= 0.3  # Decrease haze
    end
end
```

**Effect**: Evader monitors pursuers precisely â†’ Effective escape

---

## 3. è¨­è¨ˆåŸå‰‡ã¨ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³

### 3.1 Hazeåˆ¶å¾¡ã‚’ä½¿ã†ã¹ãå ´é¢

#### âœ… é©ã—ã¦ã„ã‚‹çŠ¶æ³

1. **æ³¨æ„é…åˆ†ãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯**
   - è¤‡æ•°ã®ç«¶åˆã™ã‚‹ç›®çš„ï¼ˆæ¢ç´¢ vs å®‰å…¨æ€§ï¼‰
   - é™ã‚‰ã‚ŒãŸè¨ˆç®—è³‡æº
   - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ„æ€æ±ºå®š

2. **è¡Œå‹•é§†å‹•åŠ›ãŒæ˜ç¢ºã«å®šç¾©ã•ã‚Œã¦ã„ã‚‹**
   - æ˜ç¢ºãªPragmatic Valueé …ãŒå­˜åœ¨
   - æœ›ã¾ã—ã„è¡Œå‹•ãŒEFEæœ€å°åŒ–ã¨ã—ã¦è¡¨ç¾å¯èƒ½

3. **ç©ºé–“æ§‹é€ ãŒé‡è¦**
   - ç•°ãªã‚‹æ–¹å‘ãŒç•°ãªã‚‹é‡è¦æ€§ã‚’æŒã¤
   - è·é›¢ä¾å­˜çš„ãªæƒ…å ±ä¾¡å€¤

4. **åˆ†æ•£åˆ¶å¾¡ãŒæœ›ã¾ã—ã„**
   - ä¸­å¤®åˆ¶å¾¡å™¨ãªã—
   - å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒè‡ªå¾‹çš„ã«è¡Œå‹•
   - å¤§è¦æ¨¡ç¾¤ã‚Œã¸ã®ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ï¼ˆ100+ agentsï¼‰

#### âŒ é©ã—ã¦ã„ãªã„çŠ¶æ³

1. **æ—¢å­˜ã®è¡Œå‹•é§†å‹•åŠ›ãŒãªã„**
   - Hazeã¯å‹•æ©Ÿã‚’ç”Ÿæˆã§ããšã€å¤‰èª¿ã®ã¿å¯èƒ½
   - ä¾‹: å¼•åŠ›é …ã®ãªã„é›†ç´„ã‚¿ã‚¹ã‚¯ â†’ Hazeç„¡åŠ¹

2. **å…¨æ–¹å‘å¯¾ç§°ãªã‚¿ã‚¹ã‚¯**
   - åˆ©ç”¨å¯èƒ½ãªç©ºé–“æ§‹é€ ãŒãªã„
   - ä¾‹: ãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯ï¼ˆhazeã®åŠ¹æœãªã—ï¼‰

3. **å³å¯†ãªåˆ¶å¾¡ãŒå¿…è¦**
   - Hazeã¯**ã‚½ãƒ•ãƒˆã‚¬ã‚¤ãƒ€ãƒ³ã‚¹**ã§ã‚ã‚Šã€ãƒãƒ¼ãƒ‰åˆ¶ç´„ã§ã¯ãªã„
   - ä¾‹: ç²¾å¯†ãªè»Œé“è¿½å¾“ï¼ˆæ˜ç¤ºçš„åˆ¶å¾¡ã‚’ä½¿ç”¨ã™ã¹ãï¼‰

### 3.2 Hazeæˆ¦ç•¥é¸æŠãƒãƒˆãƒªã‚¯ã‚¹

| ã‚¿ã‚¹ã‚¯ç‰¹æ€§ | æ¨å¥¨Hazeæˆ¦ç•¥ | æ ¹æ‹  |
|-----------|------------|------|
| **æ¢ç´¢ä¸»ä½“** | Mid-distance haze (+) | éå‰°è¨ˆç”»ã®æŠ‘åˆ¶ |
| **ç›®æ¨™è¿½å¾“** | ç›®æ¨™æ–¹å‘ã®Low haze | æ³¨æ„ã®é›†ä¸­ |
| **å›é¿ä¸»ä½“** | Near-distance haze (âˆ’) | å®‰å…¨æ€§ç¶­æŒ |
| **å”èª¿ãŒå¿…è¦** | Environmental haze (Stigmergy) | é–“æ¥çš„ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ |
| **å¤šãƒ•ã‚§ãƒ¼ã‚ºã‚¿ã‚¹ã‚¯** | Adaptive haze (æ™‚å¤‰) | æ–‡è„ˆã«å¿œã˜ãŸå¤‰èª¿ |
| **éå¯¾ç§°ç’°å¢ƒ** | Directional haze | æœ‰åˆ©ãªæ–¹å‘ã¸ã®ãƒã‚¤ã‚¢ã‚¹ |

**(+)**: Hazeã‚’å¢—åŠ ã€**(âˆ’)**: Hazeã‚’æ¸›å°‘

### 3.3 ã‚ˆãã‚ã‚‹è½ã¨ã—ç©´

#### è½ã¨ã—ç©´1: éå‰°å¤‰èª¿
**ç—‡çŠ¶**: æ¥µç«¯ãªhazeå€¤ï¼ˆ>10Ã—ï¼‰â†’ è¡Œå‹•ä¸å®‰å®šåŒ–

**ä¾‹**:
```julia
h_matrix[:, :] *= 100.0  # æ¥µç«¯ã™ãã‚‹ï¼
```

**åŠ¹æœ**: Precision â†’ 0 â†’ ä¿¡å¿µã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ â†’ âˆ â†’ ã‚«ã‚ªã‚¹çš„æŒ™å‹•

**è§£æ±ºç­–**: ç©ã‚„ã‹ãªmultiplierï¼ˆ2-5Ã—ï¼‰ã€æ®µéšçš„ãªé·ç§»

#### è½ã¨ã—ç©´2: å®‰å…¨æ€§é‡è¦æƒ…å ±ã®ç„¡è¦–
**ç—‡çŠ¶**: Near-distanceã®é«˜haze â†’ è¡çªå¢—åŠ 

**ä¾‹**:
```julia
# å±é™º: Near-distanceã®hazeå¢—åŠ 
h_matrix[1:2, :] *= 5.0
```

**åŠ¹æœ**: è¡çªå›é¿èƒ½åŠ›ä½ä¸‹ â†’ å®‰å…¨æ€§é•å

**è§£æ±ºç­–**: Near-distance precisionã¯å¸¸ã«é«˜ãä¿ã¤ï¼ˆhaze â‰¤ 1.0Ã—ï¼‰

#### è½ã¨ã—ç©´3: ãƒ­ãƒã‚¹ãƒˆæ€§æ¤œè¨¼ãªã—ã®éå¯¾ç§°Haze
**ç—‡çŠ¶**: Left/Rightéå¯¾ç§°hazeãŒseedä¾å­˜ã®æ€§èƒ½ã‚’ç¤ºã™

**ä¾‹**:
```julia
# LeftåŠçƒã®hazeå¢—åŠ 
h_matrix[:, left_bins] *= 2.0
```

**åŠ¹æœ**: ã‚«ã‚ªã‚¹çš„æ„Ÿåº¦ â†’ äºˆæ¸¬ä¸èƒ½ãªæ€§èƒ½ï¼ˆåˆ†æ•£ Â±6%ï¼‰

**è§£æ±ºç­–**: â‰¥10 seedsã§æ¤œè¨¼ã€å¯èƒ½ãªé™ã‚Šå¯¾ç§°æˆ¦ç•¥ã‚’ä½¿ç”¨

#### è½ã¨ã—ç©´4: ç©ºé–“æ–‡è„ˆãªã—ã®ãƒãƒ£ãƒ³ãƒãƒ«é¸æŠçš„Haze
**ç—‡çŠ¶**: å˜ä¸€SPMãƒãƒ£ãƒ³ãƒãƒ«ã®å¤‰èª¿ â†’ æ€§èƒ½åŠ£åŒ–

**ä¾‹**:
```julia
# ç„¡åŠ¹: Radial velocityã®ã¿ã®haze
spm_modulated[2, :, :] ./= 3.0  # Channel 2 = Radial
```

**åŠ¹æœ**: æƒ…å ±ã®ä¸æ•´åˆ â†’ è¡çªå¢—åŠ ï¼ˆ+46 eventsï¼‰

**è§£æ±ºç­–**: Hazeã‚’å…¨ãƒãƒ£ãƒ³ãƒãƒ«ã«ä¸€æ§˜é©ç”¨ã€ç©ºé–“çš„ã«å¤‰èª¿ï¼ˆr, Î¸ï¼‰

### 3.4 æ¤œè¨¼ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

Hazeæˆ¦ç•¥ã‚’å±•é–‹ã™ã‚‹å‰ã«ç¢ºèªï¼š

- [ ] **å®‰å…¨æ€§**: Near-distanceè¡çªãŒè‘—ã—ãå¢—åŠ ã—ãªã„ï¼ˆ<10%ï¼‰
- [ ] **ãƒ­ãƒã‚¹ãƒˆæ€§**: Seedé–“ã®æ€§èƒ½åˆ†æ•£ãŒè¨±å®¹ç¯„å›²å†…ï¼ˆ<20%ï¼‰
- [ ] **ã‚¿ã‚¹ã‚¯æ”¹å–„**: ç›®æ¨™æŒ‡æ¨™ãŒBaselineæ¯”â‰¥3%æ”¹å–„
- [ ] **ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•è¨±å®¹**: åˆ¶å¾¡ã‚³ã‚¹ãƒˆå¢—åŠ ãŒæ€§èƒ½å‘ä¸Šã§æ­£å½“åŒ–ã•ã‚Œã‚‹
- [ ] **ç†è«–çš„æ•´åˆæ€§**: HazeãŒæ—¢å­˜é§†å‹•åŠ›ã‚’å¤‰èª¿ã—ã€æ–°ã—ã„é§†å‹•åŠ›ã‚’ç”Ÿæˆã—ãªã„
- [ ] **Multi-seedæ¤œè¨¼**: â‰¥5å€‹ã®ãƒ©ãƒ³ãƒ€ãƒ seedã§ãƒ†ã‚¹ãƒˆ
- [ ] **Ablation study**: Hazeã®å¯„ä¸ã‚’æ¤œè¨¼ï¼ˆã‚ã‚Š/ãªã—æ¯”è¼ƒï¼‰

---

## 4. å®Ÿè£…ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### 4.1 ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ§‹é€ 

```
src_julia/
â”œâ”€â”€ control/
â”‚   â”œâ”€â”€ EPH.jl                 # EFEæœ€å°åŒ–ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©
â”‚   â”œâ”€â”€ SelfHaze.jl            # Self-hazeè¨ˆç®—
â”‚   â””â”€â”€ EnvironmentalHaze.jl   # (å°†æ¥) Environmental hazeç®¡ç†
â”œâ”€â”€ perception/
â”‚   â””â”€â”€ SPM.jl                 # Saliency Polar Map
â””â”€â”€ utils/
    â””â”€â”€ MathUtils.jl           # ãƒˆãƒ¼ãƒ©ã‚¹å¹¾ä½•
```

### 4.2 Hazeè¨ˆç®—ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

```julia
# 1. Compute SPM
spm = SPM.compute_spm(agent, env, spm_params)

# 2. Compute Self-Haze
h_self = SelfHaze.compute_self_haze(spm, eph_params)
h_matrix_self = SelfHaze.compute_self_haze_matrix(spm, eph_params)

# 3. (Optional) Sample Environmental Haze
h_env = sample_environmental_haze(env.haze_grid, agent.position, agent.orientation)

# 4. (Optional) Apply Engineered Haze
h_matrix_eng = apply_engineered_haze(h_matrix_self, strategy)

# 5. Compose Haze
h_matrix_total = max.(h_matrix_self, h_env, h_matrix_eng)

# 6. Compute Precision
Î  = SelfHaze.compute_precision_matrix(spm, h_matrix_total, eph_params)

# 7. Minimize EFE
action = EPH.decide_action(controller, agent, spm, env, preferred_velocity,
                           h_matrix_override=h_matrix_total)
```

### 4.3 æ‹¡å¼µãƒã‚¤ãƒ³ãƒˆ

#### æ‹¡å¼µ1: ã‚«ã‚¹ã‚¿ãƒ Hazeæˆ¦ç•¥
```julia
module CustomHazeStrategy

export apply_custom_haze!

function apply_custom_haze!(
    h_matrix::Matrix{Float64},
    agent::Agent,
    env::Environment,
    task_context::Dict
)::Matrix{Float64}
    # User-defined logic
    # Example: Task-phase-dependent modulation
    if task_context["phase"] == :collecting
        # Increase precision toward target
        ...
    elseif task_context["phase"] == :driving
        # Decrease precision behind
        ...
    end

    return h_matrix
end

end
```

#### æ‹¡å¼µ2: å­¦ç¿’ã•ã‚ŒãŸHazeãƒãƒªã‚·ãƒ¼
```julia
# Haze policy as neural network
struct LearnedHazePolicy
    network::Chain  # Flux.jl neural network
end

function (policy::LearnedHazePolicy)(spm::Array{Float64, 3}, agent_state::Vector{Float64})
    input = vcat(vec(spm), agent_state)
    h_matrix_flat = policy.network(input)
    h_matrix = reshape(h_matrix_flat, (Nr, NÎ¸))
    return h_matrix
end
```

Train via Reinforcement Learning:
```julia
# Reward = task_performance - Î» * control_cost
reward = coverage_rate - 0.1 * sum(actions.^2)
```

---

## 5. ç†è«–çš„æ€§è³ª

### 5.1 åæŸæ€§ã¨å®‰å®šæ€§

#### å‘½é¡Œ1: EFEå‹¾é…æµ
ç©ã‚„ã‹ãªæ¡ä»¶ä¸‹ï¼ˆæœ‰ç•ŒHazeã€Lipschitzé€£ç¶šSPMï¼‰ã«ãŠã„ã¦ã€è¡Œå‹•é¸æŠãƒ—ãƒ­ã‚»ã‚¹ï¼š

$$
a_{k+1} = a_k - \eta \nabla_a G(a_k; \mathcal{H})
$$

ã¯ $G(a; \mathcal{H})$ ã®å±€æ‰€æœ€å°ã«åæŸã™ã‚‹ã€‚

**è¨¼æ˜ã‚¹ã‚±ãƒƒãƒ**:
1. $G(a; \mathcal{H})$ ã¯2å›å¾®åˆ†å¯èƒ½ï¼ˆZygoteè‡ªå‹•å¾®åˆ†ï¼‰
2. å›ºå®šã‚¹ãƒ†ãƒƒãƒ—ã‚µã‚¤ã‚º $\eta$ ã®å‹¾é…é™ä¸‹ã¯ã€å¼·å‡¸ãª $G$ ã«å¯¾ã—ã¦åæŸ
3. Hazeã¯å‹¾é…ã®å¤§ãã•ã‚’å¤‰èª¿ã™ã‚‹ãŒã€åŸºæœ¬çš„ãªæ™¯è¦³æ§‹é€ ã¯å¤‰ãˆãªã„

**å«æ„**: Hazeã¯åæŸã‚’ä¸å®‰å®šåŒ–ã›ãšã€åæŸé€Ÿåº¦ã¨å±€æ‰€æœ€å°ã®é¸æŠã®ã¿ã‚’å¤‰èª¿ã™ã‚‹ã€‚

#### å‘½é¡Œ2: Hazeæ„Ÿåº¦
æœ€çµ‚è¡Œå‹•ã®Hazeæ‘‚å‹•ã«å¯¾ã™ã‚‹æ„Ÿåº¦ã¯æœ‰ç•Œï¼š

$$
\left\| \frac{\partial a^*}{\partial h(r,\theta)} \right\| \leq C \cdot \Pi_{base}(r,\theta) \cdot \alpha
$$

ã“ã“ã§ $C$ ã¯SPMå¤§ãã•ã«ä¾å­˜ã™ã‚‹å®šæ•°ã€‚

**å«æ„**: HazeåŠ¹æœã¯å±€æ‰€åŒ–ã•ã‚Œã‚‹â€”é æ–¹ã®binã®æ‘‚å‹•ã¯æœ€å°é™ã®å½±éŸ¿ã—ã‹ä¸ãˆãªã„ã€‚

### 5.2 å‰µç™ºç‰¹æ€§

#### ç‰¹æ€§1: Environmental Hazeã«ã‚ˆã‚‹è‡ªå·±çµ„ç¹”åŒ–

ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒç’°å¢ƒHazeã‚’å †ç©ã•ã›ã‚‹å ´åˆï¼š

$$
\frac{\partial \mathcal{H}_{env}(x,y)}{\partial t} = -\gamma \mathcal{H}_{env} + \sum_{i} \delta(\mathbf{p}_i - (x,y)) \cdot h_{deposit}
$$

ã“ã‚Œã¯**ã‚¹ãƒ†ã‚£ã‚°ãƒãƒ¼ã‚¸ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—**ã‚’ç”Ÿæˆï¼š
- äº¤é€šé‡ã®å¤šã„ã‚¨ãƒªã‚¢ â†’ é«˜Hazeå †ç© â†’ åç™ºåŠ¹æœï¼ˆ$h_{deposit} > 0$ ã®å ´åˆï¼‰
- äº¤é€šé‡ã®å°‘ãªã„ã‚¨ãƒªã‚¢ â†’ ä½Haze â†’ å¼•åŠ›åŠ¹æœï¼ˆç›¸å¯¾çš„ï¼‰

**å‰µç™ºè¡Œå‹•**: æ˜ç¤ºçš„ãªå”èª¿ãªã—ã§ç©ºé–“ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆçµŒè·¯ã€ç¸„å¼µã‚Šï¼‰ãŒå½¢æˆ

#### ç‰¹æ€§2: ç›¸è»¢ç§»
Hazeå¤‰èª¿ã•ã‚ŒãŸå¼•åŠ›/åç™ºåŠ›ã‚’æŒã¤ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã«ãŠã„ã¦ï¼š

$$
\text{Compactness}(\mathcal{H}) = f(\lambda_{attract}, \lambda_{repel}, \mathcal{H})
$$

ã¯è‡¨ç•ŒHazeé–¾å€¤ã§**åˆ†å²**ã‚’ç¤ºã™ï¼š
- Low haze: å¯†é›†çš„é›†ç´„
- High haze: åˆ†æ•£çš„æ¢ç´¢

**å¿œç”¨**: å‹•çš„ç›¸åˆ¶å¾¡ï¼ˆä¾‹ï¼šShepherding ã«ãŠã‘ã‚‹ Collecting â†” Drivingï¼‰

---

## 6. é–¢é€£ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¨ã®æ¯”è¼ƒ

### 6.1 vs. Potential Fields (Khatib, 1986)

| å´é¢ | Potential Fields | EPH Haze |
|--------|------------------|----------|
| **åˆ¶å¾¡ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ** | æ˜ç¤ºçš„ãªåŠ› | æš—é»™çš„ãªprecisionå¤‰èª¿ |
| **å±€æ‰€æœ€å°** | ãƒˆãƒ©ãƒƒãƒ—ã«é™¥ã‚Šã‚„ã™ã„ | èªè­˜çš„æ¢ç´¢ã§è„±å‡º |
| **ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£** | O(NÂ²) agent-agent | O(1) per agent (SPM-based) |
| **é©å¿œæ€§** | å›ºå®šãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ« | å‹•çš„Self-haze |
| **é€šä¿¡** | ã—ã°ã—ã°å¿…è¦ | ä¸è¦ï¼ˆStigmergyã¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰ |

**EPHã®å„ªä½æ€§**: èªè­˜çš„æ¢ç´¢ã«ã‚ˆã£ã¦å±€æ‰€æœ€å°ã‚’å›é¿ï¼ˆé«˜ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ â†’ ãƒˆãƒ©ãƒƒãƒ—ã‹ã‚‰ã®ãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯è„±å‡ºï¼‰

### 6.2 vs. Ant Colony Optimization (Dorigo, 1992)

| å´é¢ | ACO | EPH Haze |
|--------|-----|----------|
| **ã‚·ã‚°ãƒŠãƒ«** | Pheromone (ä¾¡å€¤) | Haze (precision) |
| **æ„å‘³è«–** | "è‰¯ã„çµŒè·¯" | "ä¿¡é ¼ã§ãã‚‹æƒ…å ±" |
| **å¼·åŒ–** | æ­£ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ | æ–‡è„ˆä¾å­˜ |
| **è¡¨ç¾** | ã‚¹ã‚«ãƒ©ãƒ¼å€¤ | ç©ºé–“ãƒ†ãƒ³ã‚½ãƒ« (r, Î¸) |
| **ç†è«–** | ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ | FEP/Active Inference |

**EPHã®å„ªä½æ€§**: åŸç†çš„ãªç†è«–åŸºç›¤ï¼ˆFEPï¼‰ã€ã‚ˆã‚Šè±Šã‹ãªç©ºé–“æ§‹é€ 

### 6.3 vs. Flocking Models (Reynolds, 1987; Couzin, 2002)

| å´é¢ | Flocking | EPH |
|--------|----------|-----|
| **ãƒ«ãƒ¼ãƒ«** | æ‰‹ä½œã‚Šï¼ˆSeparation, Alignment, Cohesionï¼‰ | EFEæœ€å°åŒ–ã‹ã‚‰å‰µç™º |
| **ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ€§** | æ–°ã—ã„è¡Œå‹•ã«ã¯æ–°ã—ã„ãƒ«ãƒ¼ãƒ«ã‚’è¿½åŠ  | Pragmatic Valueé …ã‚’èª¿æ•´ |
| **æ³¨æ„æ©Ÿæ§‹** | å…¨ã¦ã®éš£æ¥å€‹ä½“ã‚’ç­‰ã—ãé‡ã¿ä»˜ã‘ | Hazeå¤‰èª¿ã•ã‚ŒãŸæ³¨æ„ |
| **ç†è«–çš„åŸºç›¤** | é‹å‹•å­¦çš„ | Active Inferenceï¼ˆãƒ™ã‚¤ã‚ºçš„ï¼‰ |

**EPHã®å„ªä½æ€§**: çµ±ä¸€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ï¼ˆãƒ«ãƒ¼ãƒ«å¢—æ®–ãªã—ï¼‰ã€ç”Ÿç‰©å­¦çš„åŸºç›¤

---

## 7. ä»Šå¾Œã®ç ”ç©¶æ–¹å‘

### 7.1 é©å¿œçš„Hazeãƒãƒªã‚·ãƒ¼

**å•ã„**: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯æœ€é©ãªHazeæˆ¦ç•¥ã‚’å­¦ç¿’ã§ãã‚‹ã‹ï¼Ÿ

**ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ**: ãƒ¡ã‚¿å¼·åŒ–å­¦ç¿’

```python
# Meta-RL for haze policy
policy_network = HazePolicyNet(input_dim, output_dim)

for episode in episodes:
    task = sample_task()  # Exploration, Shepherding, Foraging, ...
    h_matrix = policy_network(spm, task_context)
    reward = task_performance(h_matrix)
    policy_network.update(reward)
```

**æœŸå¾…ã•ã‚Œã‚‹æˆæœ**: æ‰‹ä½œã‚Šæˆ¦ç•¥ã‚’ä¸Šå›ã‚‹ã‚¿ã‚¹ã‚¯ç‰¹åŒ–å‹Hazeãƒãƒªã‚·ãƒ¼

### 7.2 ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆHazeäº¤æ¸‰

**å•ã„**: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯å”èª¿ã®ãŸã‚ã«Hazeè¨­å®šã‚’äº¤æ¸‰ã§ãã‚‹ã‹ï¼Ÿ

**ã‚·ãƒŠãƒªã‚ª**: è¤‡æ•°ã®çŠ¬ã«ã‚ˆã‚‹Shepherding
- Dog A ã¯ç¾Šæ–¹å‘ã«ä½Hazeã‚’æœ›ã‚€ï¼ˆç¾Šã«æ³¨ç›®ï¼‰
- Dog B ã¯ Dog A æ–¹å‘ã«é«˜Hazeã‚’æœ›ã‚€ï¼ˆè¡çªå›é¿ï¼‰

**ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ**: ã‚²ãƒ¼ãƒ ç†è«–çš„Hazeæœ€é©åŒ–
$$
\mathcal{H}^* = \arg\min_{\mathcal{H}} \sum_{i} G_i(a_i; \mathcal{H}) + \lambda \cdot \text{Nashå‡è¡¡ã‚³ã‚¹ãƒˆ}
$$

### 7.3 éšå±¤çš„Hazeåˆ¶å¾¡

**å•ã„**: å€‹ä½“ã®Hazeï¼ˆãƒŸã‚¯ãƒ­ï¼‰ã¨é›†å›£ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆãƒã‚¯ãƒ­ï¼‰ã¯ã©ã†ç›¸äº’ä½œç”¨ã™ã‚‹ã‹ï¼Ÿ

**ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ**: Hazeå‹•åŠ›å­¦ã®å¹³å‡å ´ç†è«–

$$
\frac{\partial \rho(\mathbf{x}, \mathcal{H}, t)}{\partial t} = -\nabla \cdot (\rho \mathbf{v}(\mathcal{H})) + D \nabla^2 \rho
$$

ã“ã“ã§ $\rho$ ã¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå¯†åº¦ã€$\mathbf{v}(\mathcal{H})$ ã¯Hazeä¾å­˜é€Ÿåº¦å ´

**æœŸå¾…ã•ã‚Œã‚‹çŸ¥è¦‹**: å±€æ‰€Hazeãƒ«ãƒ¼ãƒ«ã‹ã‚‰ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³å½¢æˆã¸ã®æ¡ä»¶

### 7.4 å®Ÿä¸–ç•Œãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹æ¤œè¨¼

**å•ã„**: EPH-Hazeã¯ãƒã‚¤ã‚ºã®ã‚ã‚‹ã‚»ãƒ³ã‚µãƒ¼ã‚’æŒã¤å®Ÿæ©Ÿãƒ­ãƒœãƒƒãƒˆã§æ©Ÿèƒ½ã™ã‚‹ã‹ï¼Ÿ

**èª²é¡Œ**:
- Lidar/ã‚«ãƒ¡ãƒ©ãƒã‚¤ã‚ºä¸‹ã§ã®SPMè¨ˆç®—
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‹¾é…è¨ˆç®—ï¼ˆçµ„ã¿è¾¼ã¿ã‚·ã‚¹ãƒ†ãƒ ï¼‰
- ãƒãƒ«ãƒãƒ­ãƒœãƒƒãƒˆé€šä¿¡é…å»¶

**ãƒ†ã‚¹ãƒˆãƒ™ãƒƒãƒ‰**: Turtlebot3 ã‚¹ãƒ¯ãƒ¼ãƒ ï¼ˆ5-10å°ï¼‰

---

## 8. çµè«–

### 8.1 è²¢çŒ®ã®ã¾ã¨ã‚

1. **æ±ç”¨ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯**: Haze Tensor Controlã¯**æ±ç”¨çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ**ã§ã‚ã‚Šã€Shepherdingã«é™å®šã•ã‚Œãªã„
2. **3ã¤ã®åˆ¶å¾¡ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ **: Self-Hazingã€Environmental Hazingã€Engineered Hazing
3. **è¨­è¨ˆåŸå‰‡**: Hazeæˆ¦ç•¥é¸æŠã®ãŸã‚ã®æ¤œè¨¼æ¸ˆã¿ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³
4. **ç†è«–çš„åŸºç›¤**: FEPã«åŸºã¥ãprecisioné‡ã¿ä»˜ãActive Inference
5. **æ‹¡å¼µæ€§**: ã‚«ã‚¹ã‚¿ãƒ Hazeæˆ¦ç•¥ã®ãŸã‚ã®ãƒ¢ã‚¸ãƒ¥ãƒ©ãƒ¼ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### 8.2 é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ

#### ç ”ç©¶è€…å‘ã‘
- **Hazeã¯å¤‰èª¿å™¨ã§ã‚ã‚‹**: æ—¢å­˜ã®é§†å‹•åŠ›ã‚’å½¢æˆã™ã‚‹ãŒã€ãã‚Œè‡ªä½“ã‚’ç”Ÿæˆã™ã‚‹ã‚‚ã®ã§ã¯ãªã„
- **ç©ºé–“é¸æŠæ€§**: è·é›¢ã¨è§’åº¦ã®æ¬¡å…ƒãŒéµ
- **ãƒ­ãƒã‚¹ãƒˆæ€§ãŒé‡è¦**: è¤‡æ•°ã®ã‚·ãƒ¼ãƒ‰ï¼ˆâ‰¥5ï¼‰ã§æ¤œè¨¼ã™ã‚‹ã“ã¨
- **ãƒã‚¬ãƒ†ã‚£ãƒ–ãªçµæœã«ã‚‚ä¾¡å€¤ãŒã‚ã‚‹**: Compactnessä¸å¤‰æ€§å®Ÿé¨“ã¯é™ç•Œã‚’æ˜ç¢ºåŒ–

#### å®Ÿå‹™è€…å‘ã‘
- **ã‚·ãƒ³ãƒ—ãƒ«ã‹ã‚‰å§‹ã‚ã‚‹**: ã¾ãšSelf-Hazeã€æ¬¡ã«Environmentalã€æœ€å¾Œã«Engineered
- **å®‰å…¨æ€§ã‚’æ¤œè¨¼**: è¿‘è·é›¢precisionã¯é«˜ãç¶­æŒã™ã‚‹ã“ã¨
- **ã‚¿ã‚¹ã‚¯ç‰¹åŒ–ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°**: ä¸‡èƒ½ãªHazeè¨­å®šã¯å­˜åœ¨ã—ãªã„
- **ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ãŒå­˜åœ¨**: æ€§èƒ½ vs åˆ¶å¾¡ã‚³ã‚¹ãƒˆ vs ãƒ­ãƒã‚¹ãƒˆæ€§

### 8.3 ãƒ“ã‚¸ãƒ§ãƒ³

EPH Haze Tensor Controlã®æœ€çµ‚ç›®æ¨™ï¼š

> **ã€ŒçŸ¥çš„ã«æ³¨æ„ã‚’é…åˆ†ã—ã€å‹•çš„ç’°å¢ƒã«é©å¿œã—ã€æœ€å°é™ã®é€šä¿¡ã§è‡ªå·±çµ„ç¹”åŒ–ã™ã‚‹ç¾¤ã‚Œâ€”å…¨ã¦ãŒè‡ªç”±ã‚¨ãƒãƒ«ã‚®ãƒ¼åŸç†ã«åŸºã¥ã„ã¦ã€‚ã€**

---

## å‚è€ƒæ–‡çŒ®

### EPHãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
- [EmergentPerceptualHaze_EPH.md](./EmergentPerceptualHaze_EPH.md) - Core EPH theory
- [SaliencyPolarMap_SPM.md](./SaliencyPolarMap_SPM.md) - Perceptual representation
- [Haze Tensor Effect Report](../experimental_reports/haze_tensor_effect.md) - Spatial scan validation

### Active Inferenceæ–‡çŒ®
- Friston, K. J. (2010). The free-energy principle: a unified brain theory? *Nature Reviews Neuroscience*, 11(2), 127-138.
- Parr, T., & Friston, K. J. (2019). Generalised free energy and active inference. *Biological cybernetics*, 113(5-6), 495-513.

### ç¾¤çŸ¥èƒ½æ–‡çŒ®
- Reynolds, C. W. (1987). Flocks, herds and schools: A distributed behavioral model. *ACM SIGGRAPH*, 21(4), 25-34.
- Dorigo, M., et al. (1996). Ant system: optimization by a colony of cooperating agents. *IEEE Transactions on Systems, Man, and Cybernetics*, Part B, 26(1), 29-41.
- Couzin, I. D., et al. (2002). Collective memory and spatial sorting in animal groups. *Journal of theoretical biology*, 218(1), 1-11.

---

**Document Status**: Active Development
**Version**: 1.0
**Last Updated**: 2025-11-25
**Author**: Hiroshi Igarashi (AI-DLC, Tokyo Denki University)
**License**: Internal research document
