# crlEPH-dlc: Emergent Perceptual Haze (EPH) Framework

[![Julia](https://img.shields.io/badge/Julia-1.9%2B-9558B2?logo=julia)](https://julialang.org/)
[![Python](https://img.shields.io/badge/Python-3.8%2B-3776AB?logo=python)](https://www.python.org/)
[![PyQt5](https://img.shields.io/badge/PyQt5-5.15%2B-41CD52?logo=qt)](https://www.riverbankcomputing.com/software/pyqt/)
[![License](https://img.shields.io/badge/License-Research-blue.svg)]()

A research implementation of the **Emergent Perceptual Haze (EPH)** framework for swarm intelligence, combining **Active Inference** and **Free Energy Principle** with bio-inspired perception for gradient-based multi-agent coordination.

## ğŸ¯ Overview

EPH enables multi-agent coordination through **self-hazing** - a precision modulation mechanism where agents dynamically adjust their perceptual uncertainty based on local occupancy. This creates emergent exploration-exploitation behavior without explicit communication.

### Core Concepts

- **Active Inference**: Agents minimize Expected Free Energy (EFE) through gradient descent
- **Self-Hazing**: Belief entropy modulation based on SPM occupancy (`h_self(Î©)`)
- **Prediction-Based Surprise**: Temporal surprise from prediction errors (Active Inference Phase 1)
- **Saliency Polar Map (SPM)**: Bio-inspired log-polar visual representation (V1 cortex)
- **Gradient-Based Control**: Pure gradient descent on EFE - **no force fields or repulsion**

### Key Innovation

**Collision avoidance emerges purely from gradients** - no repulsion forces, no collision detection:
```julia
# Only gradient descent on Expected Free Energy
grad = âˆ‡_a G(a) where G(a) = F_percept + Î²Â·H[q(s|a)] + Î»Â·M_meta + Î³_infoÂ·I
action â† action - Î·Â·grad
```

**Surprise-driven exploration**: Prediction errors drive epistemic behavior
```julia
Surprise = Î£_{r,Î¸} Î [r,Î¸] Â· (SPM_observed - SPM_predicted)Â² Â· dist_weight
High surprise â†’ Information gain â†’ Exploration
```

High occupancy â†’ Low self-haze â†’ High precision â†’ Strong collision avoidance
Low occupancy â†’ High self-haze â†’ Low precision â†’ Exploratory behavior

## ğŸš€ Quick Start

### Prerequisites

- **Julia 1.9+** (via [juliaup](https://github.com/JuliaLang/juliaup))
- **Python 3.8+** with **PyQt5** (for visualization)
- **ZeroMQ** (bundled with Julia/Python packages)

### Installation

```bash
# Clone repository
git clone <repository-url>
cd crlEPH-dlc

# Install Julia dependencies
cd src_julia
julia --project=. -e 'using Pkg; Pkg.instantiate()'
cd ..

# Install Python dependencies (PyQt5 viewer)
pip install -r requirements.txt
```

### Run Simulation

```bash
# Full simulation with PyQt5 dashboard
./scripts/run_experiment.sh

# Julia server only (headless)
cd src_julia && julia --project=. main.jl

# Python viewer only (requires server running)
python viewer.py
```

Press `Ctrl+C` to stop. The script automatically cleans up ZeroMQ ports.

## ğŸ“Š PyQt5 Dashboard Visualization

The integrated PyQt5 viewer displays:

### Left Panel: Simulation View
- **Agents**: Red (tracked Agent 1), Blue (others)
- **FOV Sectors**: Semi-transparent field of view
- **Gradient Arrow (Red)**: Shows `-âˆ‡G` descent direction
  - Longer arrow = stronger gradient
  - Points away from obstacles
- **Frame & Coverage**: Real-time metrics

### Right Panel: Real-Time Plots

**Top Row (3 plots)**:
1. **Expected Free Energy (EFE)** - Total cost function
2. **Belief Entropy** - Combined spatial + temporal uncertainty
3. **Surprise (F_percept)** - Prediction error magnitude

**Middle Row (2 plots)**:
4. **Gradient Norm** - Proves gradient-based control
5. **Self-Haze** - Precision modulation level

**Bottom Row (3 plots)**:
6-8. **SPM Heatmaps** - Occupancy, Radial Velocity, Tangential Velocity

## ğŸ“ Project Structure

```
crlEPH-dlc/
â”œâ”€â”€ README.md                     # This file
â”œâ”€â”€ CLAUDE.md                     # Developer onboarding guide
â”œâ”€â”€ requirements.txt              # Python dependencies (PyQt5 viewer)
â”‚
â”œâ”€â”€ src_julia/                    # Julia implementation (main)
â”‚   â”œâ”€â”€ main.jl                   # ZeroMQ server entry point
â”‚   â”œâ”€â”€ Simulation.jl             # Main simulation loop
â”‚   â”œâ”€â”€ Project.toml              # Julia dependencies
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â””â”€â”€ Types.jl              # Agent, Environment, EPHParams
â”‚   â”œâ”€â”€ perception/
â”‚   â”‚   â””â”€â”€ SPM.jl                # Saliency Polar Map computation
â”‚   â”œâ”€â”€ prediction/
â”‚   â”‚   â””â”€â”€ SPMPredictor.jl       # SPM prediction (Phase 1)
â”‚   â”œâ”€â”€ control/
â”‚   â”‚   â”œâ”€â”€ SelfHaze.jl           # Self-haze & precision computation
â”‚   â”‚   â””â”€â”€ EPH.jl                # Gradient-based EFE minimization
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ MathUtils.jl          # Toroidal geometry utilities
â”‚
â”œâ”€â”€ viewer.py                     # PyQt5 integrated dashboard
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ run_experiment.sh         # Launch server + viewer
â”‚
â”œâ”€â”€ doc/
â”‚   â”œâ”€â”€ EPH_Active_Inference_Derivation.md      # Mathematical derivation
â”‚   â”œâ”€â”€ EPH_Implementation_Guide_Julia.md       # Implementation guide
â”‚   â”œâ”€â”€ 20251121_Emergent Perceptual Haze (EPH).md
â”‚   â””â”€â”€ 20251120_Saliency Polar Map (SPM).md
â”‚
â””â”€â”€ archive/
    â””â”€â”€ python_legacy/            # Original Python implementation (archived)
```

## ğŸ§ª Architecture

### Communication Flow

```
Julia Server (port 5555)  â”€â”€ZeroMQ PUB/SUBâ”€â”€>  PyQt5 Viewer
     â†“                                              â†“
  Simulation                                   Integrated Dashboard
  SPM Computation                              - Simulation rendering
  SPM Prediction (Phase 1)                     - Real-time plots
  Surprise Calculation                         - SPM heatmaps
  Self-Haze Calculation                        - Gradient visualization
  EFE Gradient Descent
```

### Active Inference Pipeline (Phase 1)

```julia
# 1. Perception: Compute SPM
spm = compute_spm(agent, env, params)

# 2. Prediction: Estimate next SPM (Phase 1)
spm_predicted = predict_spm(agent.previous_spm, agent.velocity, params)

# 3. Surprise: Prediction error
surprise = Î£ Î [r,Î¸] Â· (spm - spm_predicted)Â² Â· dist_weight

# 4. Self-Hazing: Compute belief entropy
h_self = compute_self_haze(spm, params)  # Sigmoid based on occupancy
Î  = compute_precision_matrix(spm, h_self, params)

# Spatial entropy (uncertainty over space)
H_spatial = compute_belief_entropy(Î )

# Temporal entropy (prediction error variance)
H_temporal = log(var(spm - spm_predicted) + Îµ)

# Combined belief entropy
H_belief = H_spatial + H_temporal

# 5. Action Selection: Minimize Expected Free Energy
G(a) = F_percept(a, Î ) + Î²Â·H_belief + Î»Â·M_meta(a) + Î³_infoÂ·Surprise
grad = Zygote.gradient(a -> G(a), action)
action â† action - Î·Â·grad  # Pure gradient descent

# 6. Physics: Integrate velocity
position += velocity * dt
```

### Key Implementation Details

**SPM Tensor**: `(3, Nr, NÎ¸)` where:
- Channel 1: Occupancy (Gaussian splatting for differentiability)
- Channel 2: Radial velocity
- Channel 3: Tangential velocity

**Self-Haze Function**:
```julia
Î© = mean(spm[1, :, :])  # Average occupancy
h_self = h_max Â· sigmoid(-Î±(Î© - Î©_threshold))
```

**Precision Modulation**:
```julia
Î [r,Î¸] = Î _base[r,Î¸] Â· (1 - h_self)^Î³
```

**Surprise Calculation (Phase 1)**:
```julia
prediction_error = spm_current - spm_previous
surprise = Î£_{r,Î¸} Î [r,Î¸] Â· (w_occÂ·error_occÂ² + w_radÂ·error_radÂ² + w_tanÂ·error_tanÂ²) Â· dist_weight
```

**Current Parameters** (tuned for 300Ã—300 world, 10 agents):
- `Î± = 10.0` (sensitivity, was 2.0)
- `Î©_threshold = 0.05` (realistic occupancy range 0.0-0.15)
- `Î² = 1.0` (entropy weight, was 0.5)
- `Î³ = 2.0` (haze attenuation exponent)
- `Î³_info = 0.5` (information gain weight, **new in Phase 1**)
- `personal_space = 30.0` (collision buffer, was 20.0)
- `FOV = 210Â° Ã— 100px`

## ğŸ“Š Current Scenario

**Sparse Foraging Task (Phase 1: Prediction-Based Surprise)**
- **10 agents** in **300Ã—300 toroidal world** (smaller for frequent interactions)
- **No explicit goals** - pure epistemic foraging
- **Hypothesis Testing**: Agents transition between:
  1. **Isolated (high self-haze)** â†’ Exploration (high entropy)
  2. **Encountering neighbors** â†’ Surprise spike â†’ Information-seeking
  3. **Predictable environment (low self-haze)** â†’ Exploitation (collision avoidance)

**Phase 1 Features**:
- âœ… Linear SPM prediction (velocity-based extrapolation)
- âœ… Multi-channel surprise (occupancy + radial + tangential velocity)
- âœ… Temporal belief entropy (prediction error variance)
- âœ… Information gain term in EFE

**Observation**: High surprise when agents suddenly appear in FOV â†’ Active exploration

## ğŸ› ï¸ Development

### Key Commands

```bash
# Julia REPL testing
cd src_julia && julia --project=.

# Check gradient flow
julia> using Zygote
julia> gradient(a -> expected_free_energy(a, agent, spm, nothing, params), action)

# Type stability (performance)
julia> @code_warntype decide_action(controller, agent, spm, nothing)

# Check ZeroMQ port
lsof -i :5555
```

### Design Constraints

- **Differentiability**: All functions in EFE path must support Zygote AD
  - No in-place mutations (`.=`)
  - Use array comprehensions instead of loops with mutations
- **Toroidal distances**: Always use `toroidal_distance()`, never naive Euclidean
- **Coordinate systems**:
  - World: Cartesian (x, y) with wrap-around
  - Agent-relative: Polar (r, Î¸) where Î¸=0 is forward
  - SPM: Log-polar bins
- **PyQt5 Integration**: Use Qt signal/slot for safe cross-thread updates

See `CLAUDE.md` for comprehensive development guidelines.

## ğŸ“š Documentation

- **[CLAUDE.md](CLAUDE.md)**: Developer guide (architecture, commands, conventions)
- **[doc/EPH_Active_Inference_Derivation.md](doc/EPH_Active_Inference_Derivation.md)**: Mathematical derivation
- **[doc/EPH_Implementation_Guide_Julia.md](doc/EPH_Implementation_Guide_Julia.md)**: Implementation details
- **[doc/](doc/)**: Research proposals and technical specifications

## ğŸ”¬ Research Status

**Current Phase**: Active Inference Phase 1 - Prediction & Surprise

**Completed**:
- âœ… Julia-based simulation core
- âœ… SPM with Gaussian splatting (differentiable)
- âœ… **Active Inference formulation** (Expected Free Energy)
- âœ… **Self-hazing mechanism** (belief entropy modulation)
- âœ… **Gradient-based action selection** (Zygote AD)
- âœ… **Phase 1: Prediction-based surprise**
  - Linear SPM predictor
  - Multi-channel surprise calculation
  - Temporal belief entropy
  - Information gain term in EFE
- âœ… **PyQt5 integrated dashboard**
  - Unified simulation + plots window
  - Surprise plot
  - Gradient visualization
  - SPM heatmaps
- âœ… ZeroMQ communication protocol

**Key Verification**:
- âœ… **Pure gradient-based collision avoidance** (no repulsion forces)
- âœ… Gradient values visualized on screen: Red arrow shows `-âˆ‡G`
- âœ… Self-haze transitions: Isolated â†” With neighbors
- âœ… **Surprise spikes on unpredicted encounters**
- âœ… Parameter tuning: 50% self-haze change on encounter (was 3.3%)

**Next Steps**:
- **Phase 2**: GRU-based SPM predictor (learned temporal dynamics)
- **Phase 3**: Goal inference from predicted SPM
- Baseline comparisons (Random Walk, Potential Field, ACO)
- Statistical validation (coverage efficiency, interaction rates, surprise correlation)
- Scalability testing (agent count, world size)
- Mathematical analysis (convergence proofs, stability)

## ğŸ“ Theoretical Foundation

**Active Inference (Phase 1)**: Agents minimize Expected Free Energy with information gain
```
G(a) = F_percept(a) + Î²Â·H[q(s|a)] + Î»Â·M_meta(a) + Î³_infoÂ·I[a]

Where:
- F_percept = Perceptual surprise (prediction error)
- H[q(s|a)] = Belief entropy (spatial + temporal)
- M_meta = Pragmatic value (goal seeking)
- I[a] = Information gain (epistemic value)
```

**Surprise (Prediction Error)**:
```
F_percept = Î£_{r,Î¸,c} Î [r,Î¸] Â· w[c] Â· (SPM_obs[c,r,Î¸] - SPM_pred[c,r,Î¸])Â² Â· dist_decay(r)

Where c âˆˆ {occupancy, radial_vel, tangential_vel}
```

**Self-Hazing Hypothesis**:
```
Low occupancy Î© â†’ High self-haze h â†’ Low precision Î 
â†’ High covariance Î£ = Î ^(-1) â†’ High spatial entropy H_spatial
â†’ Epistemic term dominates â†’ Exploration emerges
```

**Temporal Uncertainty (Phase 1)**:
```
Prediction error variance â†’ Temporal entropy H_temporal
High H_temporal â†’ Unpredictable environment â†’ Information-seeking behavior
```

**Gradient Flow**:
```
âˆ‚G/âˆ‚a = âˆ‚F_percept/âˆ‚a + Î²Â·âˆ‚H/âˆ‚a + Î»Â·âˆ‚M_meta/âˆ‚a + Î³_infoÂ·âˆ‚I/âˆ‚a

Where F_percept penalizes moving towards occupied bins AND prediction errors:
F_percept = Î£_{r,Î¸} [occupancy[r,Î¸] Â· precision[r,Î¸] Â· alignment(a,Î¸) Â· dist_decay(r)
             + surprise[r,Î¸]]
```

## ğŸ¤ Contributing

This is a research project. For contributions:
1. Read `CLAUDE.md` for code conventions
2. Ensure Zygote-compatible code (test with `gradient()`)
3. Test with PyQt5 viewer: `./scripts/run_experiment.sh`
4. Use conventional commit messages (see `CLAUDE.md`)

## ğŸ“ License

Research prototype. License TBD.

## ğŸ”— Related Work

- **Active Inference**: Friston et al. (2010-2023)
- **Free Energy Principle**: Friston (2010)
- **Predictive Coding**: Rao & Ballard (1999)
- **Log-Polar Mapping**: Schwartz (1977), Traver & Bernardino (2010)
- **Stigmergy**: GrassÃ© (1959), Theraulaz & Bonabeau (1999)
- **Gradient-Based Swarms**: Olfati-Saber & Murray (2004), Reynolds (1987)

## ğŸ“§ Contact

For questions about this implementation, see `CLAUDE.md` or open an issue.

---

**Note**: This project transitioned from Python to Julia (2025-11-22), implemented Active Inference formulation (2025-11-22), and added prediction-based surprise (Phase 1, 2025-11-22). Legacy Python code is archived in `archive/python_legacy/`.

**Citation**: If you use this code in your research, please cite:
```bibtex
@misc{crleph2025,
  title={crlEPH-dlc: Gradient-Based Emergent Perceptual Haze with Prediction-Based Surprise},
  author={[Your Name]},
  year={2025},
  publisher={GitHub},
  journal={Active Inference Framework for Swarm Coordination},
  url={[repository-url]}
}
```
